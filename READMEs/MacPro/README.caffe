=============================================================================
Caffe notes
=============================================================================
Last updated on 8/17/16; 8/31/16; 1/13/17; 1/17/17
=============================================================================

*.  On 1/17/17, we git cloned the latest version of caffe custom.  After
much help from Tho and John Wood, we realized that this Jan 2017 version of
caffe custom was somehow trying to include public caffe header files from
/usr/local/caffe_Aug2016.  This caused huge numbers of compilation errors.
Once we manually removed the soft link /usr/local/caffe -->
/usr/local/caffe_Aug2016, we were able to build caffe custom after making
appropriate changes to Makefile.config.  We also upgraded cuda to version 8
and libcudnn to version 5.  

*.  On 1/13/17, we git cloned the latest version of the publically
available caffe onto Thinkmate.  We copied the Makefile.config from our Aug
31 build of caffe_public.  We found that we needed to keep the following
lines regarding CUDA architecture.

CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \
		-gencode arch=compute_20,code=sm_21 \
		-gencode arch=compute_30,code=sm_30 \
		-gencode arch=compute_35,code=sm_35 \
		-gencode arch=compute_50,code=sm_50 \
		-gencode arch=compute_50,code=compute_50

But otherwise, caffe public seemed to build fine on Thinkmate (modulo some
warning messages) when we changted make -j all, make test and make runtest.


*.  On 8/31/16, we git cloned the latest version of the publically
available caffe onto Titan3 and Titan1.  We copied the Makefile.config from
the caffe_custom into the public subdir.  We then were able to build
caffe_public without problems (though with some warning messages) on
Titan3/Titan1 by chanting make -j all, make test, and make runtest.

*.  On 8/17/16, we downloaded the latest version of caffe_custom from Tho's
git repository.  We only had to modify the python lines within
Makefile.config so that they refered to Anaconda.  Everything seemed to
build fine on Thinkmate after we made this small modification.

*.  On 8/14/16, we downloaded the latest public caffe version via

	git clone https://github.com/BVLC/caffe.git

Changes make to Makefile.config:

  - Uncommented the USE_CUDNN = 1 line
  - Uncomment all lines related to python anaconda
  - # Whatever else you find you need goes here.
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/local/cuda/include /usr/local/OpenCV/include /opt/boost/include
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/local/OpenCV/lib /opt/boost/lib

After making these minimal changes, we were able to build caffe_public
without problems on Thinkmate by chanting make -j all, make test, and make runtest.

*.  After lots of hacking, we were able to compile and run caffe_custom on
Titan1 and Titan3 on 7/24/16.  

*.  Tho's instructions dated 2/22/16 for installing his cudnn libraries:

cp -v /startown-gpfs/ssdws03/devdata/tho/cudnn-7.0-linux-x64-v4.0-prod.tgz ~/Downloads
cd ~/Downloads
tar -zxvf cudnn-7.0-linux-x64-v4.0-prod.tgz
cd cuda
sudo cp include/cudnn.h /usr/local/cuda/include
sudo rm -f /usr/local/cuda/lib64/libcudnn.*
sudo cp lib64/libcudnn_static.a /usr/local/cuda/lib64
sudo cp lib64/libcudnn.so.4.0.7 /usr/local/cuda/lib64
sudo ln -s /usr/local/cuda/lib64/libcudnn.so.4.0.7 /usr/local/cuda/lib64/libcudnn.so.4
sudo ln -s /usr/local/cuda/lib64/libcudnn.so.4 /usr/local/cuda/lib64/libcudnn.so

I have merged cuDNN v4 to pwin. If you are compiling pwin with the flags
DNN=1 and WITH_GPU=1, please make the following changes in order to compile
pwin:

1) Remove CUDA 7.0 if necessary. Ignore this step if you have CUDA 7.5 instead of CUDA 7.0:
sudo rm -rf /usr/local/cuda
sudo rm -rf /usr/local/cuda-7.0

2) Remove symlink to CUDA 7.0 in /opt/geo/ext:
sudo rm -rf /opt/geo/ext/cuda-7.0

3) Download and install CUDA 7.5 (http://tinyurl.com/pknol4k) if you are using CUDA 7.0. If NVIDIA driver has already been installed, do not install it here.

4) Create a symlink to the newly installed CUDA 7.5:
sudo ln -s /usr/local/cuda /opt/geo/ext/cuda-7.5

5) Run installation script to install cuDNN v4. Or use these commands:
cp -v /startown-gpfs/ssdws03/devdata/tho/cudnn-7.0-linux-x64-v4.0-prod.tgz ~/Downloads

*.  On 7/24/16, we had to install Cuda-7.5 onto Titan 3.  We needed to kill
the X-server running on Titan 3 before the cuda installation script could
work.  So we chanted

	sudo service gdm stop

After cuda 7.5 installed, we started gdm & X again on Titan 3 by chanting

	sudo service gdm start

*.  On 7/24/16, we compiled Tho's latest caffe_custom on our Thinkmate.  We
had to make the following modifications before caffe_custom would build:

1.  Uncomment out ANACONDA references in Makefile.config

2.  Reset ANACONDA_HOME --> /usr/local/anaconda in Makefile.config

3.  Within caffe's Makefile (not Makefile.config), need to add opencv_imgcodecs
(Note added on Feb 24, 2016:  We still need to manually add
opencv_imgcodecs into caffe_custom's Makefile since Tho continues to use
OpenCV-2.4.10 rather than OpenCV-3.1.0)


ifeq ($(USE_OPENCV), 1)
	LIBRARIES += opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs
endif


*.  On 6/8/16, we compiled Tho's caffe_custom on our Thinkmate after making
NO changes to his Makefile.config file.  Everything compiled and linked fine!

	make -j all
	make test or make -j test
	make runtest
        make pycaffe

*.  Caffe uses glog to perform macro-level logging.

Unless otherwise specified, glog writes to the filename "/tmp/<program
name>.<hostname>.<user name>.log.<severity level>.<date>.<time>.<pid>"
(e.g.,
"/tmp/hello_world.example.com.hamaji.log.INFO.20080709-222411.10474"). By
default, glog copies the log messages of severity level ERROR or FATAL to
standard error (stderr) in addition to log files.

*.  On 9/29/15, Tho recommended that we check to see if the publically
available caffe builds cleanly on Titan1.  So he told us to check out a
copy of caffe onto titan1 from git by chanting

	git clone https://github.com/BVLC/caffe.git

Within top level caffe folder created following git cloning, copy
Makefile.config.example onto Makefile.config.  Then edit Makefile.config as
follows 

   *** As of 11/16/15, see README.caffe.Makefile_config.public/custom! ***

Do NOT uncomment cuDNN acceleration switch within Makefile.config

Uncomment the OPENCV_VERSION := 3 line (as of Nov 16, 2015, this line
exists in the config file)

Do uncomment the *_50 lines within CUDA_ARCH.

Set MATLAB_DIR := /usr/local/MATLAB/R2013a/

Set PYTHON_LIB := /usr/lib/x86_64-linux-gnu

Set INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/local/cuda/include

If we have installed OpenCV within /usr/local/OpenCV/lib/, then be sure to
include this path within LIBRARY_DIRS.  Also need to add path to boost
libraries:

LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/local/OpenCV/lib /opt/geo/ext/boost/lib

Within caffe's Makefile (not Makefile.config), need to add opencv_imgcodecs
(for opencv3 - this issue seems to have gone away as of Nov 2015).
(Note added on Feb 24, 2016:  We still need to manually add
opencv_imgcodecs into caffe_custom's Makefile since Tho continues to use
OpenCV-2.4.10 rather than OpenCV-3.1.0)


ifeq ($(USE_OPENCV), 1)
	LIBRARIES += opencv_core opencv_highgui opencv_imgproc opencv_imgcodecs
endif

*.  On 11/16/15, we had to remove libgflags.a (and libgflags_nothreads.a)
from /usr/local/lib/ in order for caffe to successfully link against
libgflags.a sitting in /usr/lib/x86_64-linux-gnu/libgflags.a . 

*.  On 1/7/16, we learned the hard and painful way that we must remove any
previously installed caffe library within /usr/local/lib before attempting
to rebuild caffe from scratch!  Place any new libcaffe.so, libcaffe.a files
into /usr/local/lib/caffe which is unlikely to be specified within
Makefile.config...

*.  After modifying Makefile.config and Makefile, chant

	make -j all
	make test or make -j test
	make runtest

There should be no errors when we run the test suite.  If not, cuda may be
incorrectly installed.  Provided no other GPU jobs are running on the
machine, make runtest should only take a few minutes to complete.

*.  On 1/17/16, we tried multiple times to compile Tho's caffe_custom onto
our Thinkmate machine under /home/pcho/software.  We ran into some nasty
problems which required the following solutions:

  a.  Manually added the following line into Makefile (not Makefile.config!)

   # mex may invoke an older gcc that is too liberal with -Wuninitalized
   MATLAB_CXXFLAGS := $(CXXFLAGS) -Wno-uninitialized
   LINKFLAGS += -pthread -fPIC $(COMMON_FLAGS) $(WARNINGS)
   LINKFLAGS += -Wl,-rpath,/usr/local/anaconda/lib                   <---- This is the line we manually added

   b. We had to remove libgflags.a from Titan1 (and perhaps
      libgflags_nothreads.a) from /usr/local/lib in order to successfully
      compile, link and execute "make runtest".  Instead, we should have
      libgflags-dev installed as an ubuntu package.

*.  As of Nov 2015, we have to manually copy files within
caffe/include/caffe to /usr/local/include/caffe/.  Also copy
caffe_build_dir/build/src/caffe/proto/caffe.pb.h into
/usr/local/include/caffe/proto/.  Manually copy libcaffe.a and libcaffe.so
from caffe_build_dir/build/lib/ into /usr/local/lib/caffe/.

*.  Make sure $ANACONDA_HOME/lib is added to LD_LIBRARY_PATH within .cshrc
file.  Otherwise make runtest will fail.

*.  See http://caffe.berkeleyvision.orig for documentation on caffe

*.  See http://caffe.berkeleyvision.org/tutorial/ for a useful tutorial on
caffe.

*.  See http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html for 
"Blobs, Layers and Nets: anatomy of a Caffe model".

*.  In order to check out a clean copy of the publically available caffe
onto our Thinkmate, Tho directed us to the primary caffe website
(caffe.berkeleyvision.org).  Press on red "View on GitHub" button located
on LHS.  Then copy HTTPS clone URL located on RHS into a git clone terminal
command:

	git clone https://github.com/BVLC/caffe.git

*.  Tho has created a customized version of caffe which can be cloned from
apple's github:

	git clone git@github.geo.apple.com:geo-flyover/caffe_custom.git

*.  Tho showed us an example of prototxt files which perform training and
periodic testing on a validation set within
/home/pcho/software/caffe/examples/cifar10/.  

cifar10_full_solver_lr1.prototxt sets test_interval = 1000.  So testing on
a validation set is performed after every 1000 training iterations.

cifar10_full_train_test.prototxt contains both TRAIN and TEST phases.  See
top of this prototxt file for their definitions:

layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}

layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}

At end of this prototxt file, we see that the TEST phase is run through an
accuracy layer.  Both TRAIN and TEST phases are run through a loss layer.

layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}

*.  If we combine training and test network definitions within a single
prototxt file, then we must define the train/test net protocol buffer
definition via 

	net: "${EXP}/config/${NET_ID}/train.prototxt"

rather than 

	train_net: "${EXP}/config/${NET_ID}/train.prototxt"

within solver_base.prototxt.

*.  Chant "watch nvidia-smi" in order to monitor GPU memory usage via a
"top-like" utility.

*.  For generic training of barriers_a model with batch size = 30, 
Memory required for data: 9,160,488,016

*.  For training & testing of barriers_a model with test batch size = 30, 
Memory required for data: 9,158,067,372

*.  For training & testing of barriers_a model with test batch size = 1, 
Memory required for data: 305,268,924


*.  In order to login to a particular node within the gpu cluster, chant

ssh gpu0001  or
ssh gpu0003  etc

*.  On a GPU cluster machine other than gpu0001, cd to
/home/pcho/software/caffe_custom/ and then chant ./cluster_build.sh in
order to compile Tho's custom version of caffe.

Alternatively on gpu0001, cd to /home/pcho/software/caffe_custom/ and chant
make .

*.  In order to pull out "feature descriptors" from a particular layer
within a trained network, we can use the following pwin method inside
dl_dnn.cpp written by Tho:

/***** dl_dnn_extract_features
************************************************* 
* Description : Extract features using DNN
*
* Input  : dl_dnn  the deep neural net
*          in_feature_vec  the input feature vector. It can be set to NULL if
*                          assume that the forward pass has been done and just
*                          want to extract features.
*          layer_name  name of the layer to extract features
*          out_feature_vec  the output feature vector extracted at the specified
*                           layer. This needs to be pre-allocated.
*          feature_dim  the dimension of the output feature (can be get using
*                       dl_dnn_get_layer_feature_dim())
*
* Output : 0 if OK, non-zero otherwise
*******************************************************************************/
int dl_dnn_extract_features(dl_dnn_t *dl_dnn, float *in_feature_vec,
    const char *layer_name, float *out_feature_vec, int feature_dim)


On 10/29/15, Tho told us that his method is based upon the following core
caffe method within caffe_custom/src/caffe/ net.cpp

template <typename Dtype>
Dtype Net<Dtype>::ForwardFromTo(int start, int end) {
  CHECK_GE(start, 0);
  CHECK_LT(end, layers_.size());

*.  On 11/19/15, we encountered problems with caffe.pb.h not being
automatically built on our m6700 laptop running ubuntu 12.4.  We found the
following instructions online which solved this protobuf problem:

You need to generate caffe.pb.h manually using protoc as follows.

# In the directory you installed Caffe to
protoc src/caffe/proto/caffe.proto --cpp_out=.
mkdir include/caffe/proto
mv src/caffe/proto/caffe.pb.h include/caffe/proto

*.  As of 11/23/15, here is our understanding of the output generated by
Caffe's feature extraction and exported to either lmdb or leveldb 
database tables:

  - Dimension of feature vector = d.channels() where d = caffe Datum object

  - 1 "gist-like" feature vector of d.channels (e.g. 4096 floats for fc7 
    layer) floats exported per image

  -  Total number of images processed by feature extraction binary = 
     batch_size (e.g. 50 defined in imagenet_val.prototxt) * 
     num_mini_batches (e.g. 10 passed as command line argument to feature
     extraction binary) = 500

  -  If batch_size * num_mini_batches > n_images, then feature vector
     descriptors "wrap around" 

  - Both lmdb and leveldb databases hold key-value pairs.  "Values" within
    the database appear to be serialized caffe Datum classes.  The call

          curr_datum.ParseFromString(value)

    effectively "deserializes" the value byte string and reconstructs a 
    caffe Datum object in memory.  See header file caffe/proto/caffe.pb.h
    for caffe Datum object's public member functions.

*.  On 1/6/16, Tho told us that we should chant "make clean" and "make
clean_caffe" whenever he installs a new version of caffe for pwin.

*.  On 1/7/16, Tho told us that he had added a "strict_dim:false" entry
into train/test prototxt files for backwards compatability with older
versions of caffe.  But so long as we work with newly trained caffe models,
we should be able to comment out all "strict_dim:false" lines within
train/test prototxt files.

*.  Need to copy sub.sed into caffe_custom root dir in order to use John
Wood's very nice template files for finetuning caffe networks.  Make sure
sub.sed includes TEST_INTERVAL, TEST_ITER, MAX_ITER, TRAIN_BATCH and
TEST_BATCH vars!

Contents of sub.sed:

's,${DATA_ROOT},'"${DATA_ROOT}"',g;s,${DATA_ROOT1},'"${DATA_ROOT1}"',g;s,${EXP},'"${EXP}"',g;s,${EXP1},'"${EXP1}"',g;s,${TRAIN_SET},'"${TRAIN_SET}"',g;s,${TRAIN_SET1},'"${TRAIN_SET1}"',g;s,${TRAIN_SET1_WEAK},'"${TRAIN_SET1_WEAK}"',g;s,${TRAIN_SET1_STRONG},'"${TRAIN_SET1_STRONG}"',g;s,${TEST_SET},'"${TEST_SET}"',g;s,${NET_ID},'"${NET_ID}"',g;s,${FEATURE_DIR},'"${FEATURE_DIR}"',g;s,${NUM_LABELS},'"${NUM_LABELS}"',g;s,${NUM_LABELS1},'"${NUM_LABELS1}"',g;s,${NUM_LABELS_UNION},'"${NUM_LABELS_UNION}"',g;s,${BG_BIAS},'"${BG_BIAS}"',g;s,${FG_BIAS},'"${FG_BIAS}"',g;s,${TRAIN_SET_STRONG},'"${TRAIN_SET_STRONG}"',g;s,${TRAIN_SET_WEAK},'"${TRAIN_SET_WEAK}"',g;s,${BATCH_SIZE},'"${BATCH_SIZE}"',g;s,${TEST_SET_PREFIX},'"${TEST_SET_PREFIX}"',g;s,${TRAIN_STEP},'"${TRAIN_STEP}"',g;s,${TEST_INTERVAL},'"${TEST_INTERVAL}"',g;s,${TEST_ITER},'"${TEST_ITER}"',g;s,${MAX_ITER},'"${MAX_ITER}"',g;s,${TRAIN_BATCH},'"${TRAIN_BATCH}"',g;s,${TEST_BATCH},'"${TEST_BATCH}"',g'

*.  John's caffe sessions for semantic segmentation and finetuning of HOV's
are sitting in
/startown-gpfs/sputnik03/supersize/devdata/dl/experiments/archive/

*.  On 1/19/16, we intentionally removed all boost packages on M6700
laptop.  We also installed boost-1.59.0 within /opt.  We then had to
explicitly add /opt/boost/include to INCLUDE_DIRS in addition to
/opt/boost/lit within LIBRARY_DIRS inside the Makefile.config of
caffe_public.  The public version of caffe then compiled fine on M6700 and
passed all tests with no problems.

*.  Trained caffe models are sitting in subfolders of
/startown-gpfs/ssdws03/devdata/pr_models/.  On 2/29/16, Weiyu pointed us
towards the following fine-tuned AlexNet to use for traffic sign clustering
based upon global fc7-layer descriptors:

/startown-gpfs/ssdws03/devdata/pr_models/road_sign/20151023_caffenet/20151023_caffenet_c293_caffenet_iter_100000.caffemodel

*.  On 7/25/16, John Wood told us that we need to add "weight_filler" and
"bias_filler" entries into convolution and fully-connected layers within
train_base.prototxt in order to control how nodes in these layers are
randomly initialized.

*.  On 7/25/16, John Wood told us to look for netscope editor online in
order to generate nice plots of DNN architectures.

*.  On 7/25/16, John Wood told us that for classification rather than image
segmentation, "type:" = "Data" in the very first data layer definition
rather than IMAGE_SEG_DATA.  We also should not have a label_type = PIXEL
entry the data layer definition!

*.  Make sure to include an accuracy layer with train_base.prototxt for
BOTH the training and testing phases!

*. ~/software/caffe_custom/src/caffe/proto/caffe.proto contains caffe's
Phase enum type:

enum Phase {
   TRAIN = 0;
   TEST = 1;
}

*.  On 8/1/16, Tho explained to us that there are TWO outputs coming from
the network defined by the following first data layer.  The ZEROTH result
corresponds to the top "label" blob which is unaffected by the network.
The FIRST result corresponds to the ArgMax answers generated by the last
"output" layer in this network.  


name: "Face_01"

### INPUT LAYER ###

layer {
  name: "data"
  type: "MemoryData"
  top : "data"
  top : "label"
  memory_data_param {
    batch_size: 1
    channels: 3
    height: 96
    width: 96
  }
}

.
.
.

layer {
  name: "output"
  type: "ArgMax"
  bottom: "prob"
  top: "output"
  argmax_param {
    out_max_val: true
    top_k: 1
  }
}

*.  On 8/14/16, we looked inside
~software/caffe_public/src/caffe/proto/caffe.proto and confirmed that
solver_type key and RMSPROP value are deprecated.  Instead, caffe now
prefers to find 'type: "RMSProp"' sitting inside solver.prototxt

Known solver types (spelling and capitalization sensitive!):

   AdaDelta, AdaGrad, Adam, Nesterov, RMSProp, SGD

*.  Trained weights and biases within a caffe::Net<float> object net_ are
accessible via

   int n_total_params = 0;
   vector<float> params_lr = net_->params_lr();
   for(unsigned int p = 0; p < params_lr.size(); p++)
   {
      const shared_ptr<const caffe::Blob<float> > param_blob =
         net_->params().at(p);
      n_total_params += param_blob->count();
      cout << "p = " << p 
           << " param_blob.num_axes() = "
           << param_blob->num_axes()
           << " param_blob.shape_string() = "
           << param_blob->shape_string()
           << endl;
   }
   cout << "Number of total weights + biases = "
        << n_total_params << endl;


*.  On 8/16/16, John Wood recommended both subtracting off mean RGB values
from input images as well as rescaling all color values down to [-1,1]
rather than [-255,255].  After doing so, batch normalization apparently
works much better.

*.  On 1/17/17, Tho taught us that $(Q) in Makefile lines such as 

$(DYNAMIC_NAME): $(OBJS) | $(LIB_BUILD_DIR)
	@ echo LD -o $@
	$(Q)$(CXX) -shared -o $@ $(OBJS) $(VERSIONFLAGS) $(LINKFLAGS) $(LDFLAGS)
	@ cd $(BUILD_DIR)/lib; rm -f $(DYNAMIC_NAME_SHORT);   ln -s $(DYNAMIC_VERSIONED_NAME_SHORT) $(DYNAMIC_NAME_SHORT)

informs the compiler to be "quiet".  Remove the $(Q) in order to see more
verbose output when trying to debug caffe compilation.  

Note:  Comment in last line at bottom bottom of Makefile.config in order to
see verbose compiler output:

# enable pretty build (comment to see full commands)
# Q ?= @

*.  As of Jan 2017, we need to have cuda 8 installed in order to run caffe_custom.
We also need version 5 of CUDNN.  So we signed up for Nvidia's developer
program and then downloaded cuDNN v5.1 Runtime Library for Ubuntu 14.04
(Deb).  When we doubleclicked on its icon, libcudnn5 was automatically
installed onto Thinkmate.

*.  On 1/17/17, we had LOTS of trouble with getting caffe_custom to compile
Thinkmate.  It turned out that caffe_custom must NOT get confused by header
files sitting in /usr/local/include/caffe !!!  So while building
caffe_custom, we temporarily eliminated soft link /usr/local/include/caffe
which points to /usr/local/include/caffe_Aug2016.
