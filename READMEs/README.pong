==========================================================================
RL notes for Pong
==========================================================================
Last updated on 12/30/16
==========================================================================


Random play results for O(250 episodes) = O(20) epochs:
------------------------------------------------------

Paddle X looks like uniform distribution except for 2 spikes around X = 8
and X = 24

nframes/episode = 3700
reward = -20.6


Best play results to date:
-------------------------

-------------------------------------------------------------
TERMINATED EXPERIMENTS
-------------------------------------------------------------

4.  m6700:

Fri Dec 30 09:48:33 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 2
   n_weights = 65664 (FC)
base_learning_rate = 0.0003; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = 0
Discount factor gamma = 0.99
minimum epsilon = 0
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -9310

No learning after 30 epochs

5.  Repeat of expt 4

No learning after 30 epochs

-------------------------------------------------------------
RUNNING EXPERIMENTS
-------------------------------------------------------------

m6700
-----

6.  Fri Dec 30 11:25:08 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 67648 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = 0
Discount factor gamma = 0.99
minimum epsilon = 0
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -15104

7.  m6700:  repeat expt 6

Thinkmate
---------

1008.  TM:  H1 = 64; H2 = 0; replay memory = 20K; ppong

Fri Dec 30 15:10:35 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 2
   n_weights = 65664 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -39423

1009.  TM:  repeat expt 1008

10.  


Titan 1:
-------

Titan 3:
-------

===========================================================
TODO:

A.  Implement weight normalization 

B.  Implement data-dependent weight initialization

C.  Experiment with trying to extract ball and paddle posn and velocity and
forming much smaller input layer for a much smaller neural net


DONE:

A.  Fix memory leak!

B.  Revert to working with difference state rather than 1 big state
containing 2 screen states

C.  Fix exporting of each individual screen rather than every 3rd or 4th
one

G.  Trace individual weights' evolutions

F.  Perhaps experiment with 3 hidden layer neural network but only after
implementing batch normalization 

