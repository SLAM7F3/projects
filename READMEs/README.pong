=========================================================================
Deep RL notes for Pong
==========================================================================
Last updated on 1/4/17; 1/5/17; 1/6/17; 1/7/17
==========================================================================


Random play results for O(250 episodes) = O(20) epochs:
------------------------------------------------------

Paddle X looks like uniform distribution except for 2 spikes around X = 8
and X = 24

nframes/episode = 3700
reward = -20.6


Best play results to date:
-------------------------


112. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Fri Jan  6 11:59:15 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -32753
Process ID = 18416

Metrics look quite good after 1600 epochs.  


70.  T3: Corrected epoch plots; n_actions = 3; Xavier init includes sqrt(2)
0 accel penalty

Thu Jan  5 06:49:28 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -27766
Process ID = 4907

Metrics are maybe OK after 900 epochs; metrics look quite good after 2K
epochs.  Finished.


75.  T1:  1E-3 accel penalty; corrected epoch plots; n_actions = 3; 

Xavier init includes sqrt(2)

Thu Jan  5 12:36:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.0
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48568
Process ID = 18912

Metrics look OK after 250 epochs; Metrics look surprising good after 1400
epochs!  Agent beats AI 21 to 15 in screen_exports 3000 with minimal paddle
movement!  Some good, long rallies (which agent loses) near beginning of
screen exports 3000

screen_exports_3200:

Start excerpt at frame 818  (AI = 0, agent = 2); end excerpt at frame 3390
(AI = 1, agent = 5); play move skipping odd frames.  

AI = 5, agent = 15 is a also a good rally (wins)



77.  T1:  3E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2)
Thu Jan  5 12:38:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48687
Process ID = 21103

Metrics look OK after 240 epochs;  metrics look quite good after nearly
1500 epochs.   Results qualitatively similar to those for expt 75.


39.  Titan 3:  repeat expt 38; n_actions = 2

Sat Dec 31 10:27:11 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -8828
Process ID = 5324

After 1653 epochs, reward = 18.5 and plateaued; nframes/episode = 10833 and
plateaued; eventual reward = 0.18 and slowly rising; paddle Y is spiked
gaussian about X = 9 with small bump at X = 23; OK weight dists and values;
hard to see ball tracks in 0th layer weights

Agent loses to AI 11 to 20 in screen exports 2000
Agent loses to AI 19 to 20 in screen exports 2200  38.3K frames
Agent beats AI 20 to 14 in screen exports 2400     26.6K frames  
                                                     only wins from AI defect
Agent beats AI 20 to 11 in screen exports 2600     21.3K frames
                                                     more interesting play,
                                                     but first 7 wins are
						     due to defect
Agent beats AI 20 to 9 in screen exports 2800      20.6K frames
Agent beats AI 20 to 6 in screen exports 3000
Agent beats AI 20 to 3 in screen exports 4000
Agent beats AI 20 to 1 in screen exports 5000
Agent beats AI 20 to 2 in screen exports 6000

38.  Titan 3:  H1 = 32; H2 = 64; 20K replay memory; ppong with no constraints;
2 actions

Sat Dec 31 10:25:30 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -8705
Process ID = 4484

After 1681 epochs, reward = 16.6 and probably plateauing; nframes/episode =
15034 and falling; eventual reward = 0.110 and steadily rising; paddle Y is
gaussian about X = 12 with tiny shoulder at X = 23; OK weight dists and
values; hard to see ball tracks in 0th layer weights

Agent loses to AI 4 to 20 in screen exports 2000
Agent loses to AI 20 to 11 in screen exports 2600
Agent beats AI 20 to 13 in screen exports 2800; several good volleys
Agent beats AI 20 to 11 in screen exports 3000
Agent beats AI 20 to 1 in screen exports 5200; exploits AI bug

-------------------------------------------------------------
TERMINATED EXPERIMENTS
-------------------------------------------------------------

4.  m6700:

Fri Dec 30 09:48:33 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 2
   n_weights = 65664 (FC)
base_learning_rate = 0.0003; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = 0
Discount factor gamma = 0.99
minimum epsilon = 0
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -9310

No learning after 30 epochs

5.  Repeat of expt 4

No learning after 30 epochs

6.  Fri Dec 30 11:25:08 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 67648 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = 0
Discount factor gamma = 0.99
minimum epsilon = 0
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -15104

7.  m6700:  repeat expt 6

8.  TM:  H1 = 64; H2 = 0; replay memory = 20K; ppong

Fri Dec 30 15:10:35 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 2
   n_weights = 65664 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -39423

After 820 epochs, reward --> -6.4 and is rising; frames/episode --> 30256
and is rising;  eventual reward --> -0.024 and is very slowly rising;
paddle_X is a distorted guassian centered around X = 12; some signs of ball
tracks can be seen in 0th layer weights; screen exports illustrate
quasi-intelligent play!  smooth evolution of weight dists; movement in
weight values; 

9.  TM:  repeat expt 1008

After 820 epochs, reward --> -11.2 and is rising; frames/episode --> 27475
and is rising; eventual reward --> -0.048 and is very slowly rising;
paddle_X is distorted gaussian centered around X = 11; weak signs of ball
tracks in 0th layer weights; smooth evolution of weight dists; movement in
weight values;

10.  TM:  H1 = 128; H2 = 0; replay memory = 20K; ppong


Fri Dec 30 15:20:17 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 128
   layer = 2 n_nodes = 2
   n_weights = 131328 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -40016

After 470 epochs, reward --> -12.5 and is rising; frames/episode --> 23385
and is rising; eventual reward --> -0.065 and is very slowly rising;
paddle_X is distorted gaussian centered around X = 12; weak signs of ball
tracks in 0th layer weights; smooth evolution of weight dists; movement in
weight values;

11. TM:  repeat expt 10
After 470 epochs, results are qualitatively similar to those for expt 10


12.  Titan 3:  H1 = 64; H2 = 32; replay memory = 20K; ppong

Fri Dec 30 15:24:54 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 67648 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -40292

After 530 epochs, reward --> 2.224 and increasing; frames/episode --> 31925
and maybe increasing; eventual reward --> -0.0046 and very slowly rising;
paddle_X is distorted gaussian around X = 11 with bump at X = 24; smooth
evolution in weight dists; movement in weight values; weak signs of ball
tracks in 0th layer weights;

agent beats AI 20 to 17 in screen exports 2000
agent beats AI 20 to 10 in screen exports 2250
agent beats AI 20 to 7 in screen exports 2500

After 780 epochs, reward --> 15.58 and rising; nframes/episode --> 16354
and falling after peaking around 32K; paddle_X is distorted gaussian around
X = 10 with small bump at X=24; eventual reward --> 0.059 and slowly rising

13.  Titan 3:  repeat expt 12

After 550 epochs, reward --> 7.09 and rising; nframes/episode --> 27037 and
falling after having peaked around 31K; eventual reward --> -0.0079; paddle
X is gaussian around X = 11 with secondary peak at X = 24; screen exports
illustrate definite intelligent pong play!

After 780 epochs, reward --> 10.45 and rising; nframes/episode --> 25325
and falling after peaking around 32K; paddle X is distorted gaussian around
X = 12 with small bump at X = 24; eventual reward = 0.037 and slowly rising

agent beats AI 20 to 17 in screen exports 2250
agent beats AI 20 to 8 in screen exports 2500

14.  Titan 3: H1 = 128; H2 = 32; replay memory = 20K; ppong

Fri Dec 30 15:26:43 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 128
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 135232 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -40402

After 190 epochs, reward --> -13.5 and is rising; nframes/episode --> 19137
and is rising; paddle_X is distorted gaussian around X = 11 with secondary
bump at X = 24; eventual reward --> -0.087 and slowly rising; very weak
signs of ball tracks in 0th layer weights;

15.  Titan 3:  repeat expt 14
After 190 epochs, qualitatively similar results as those for expt 14;


16.  Titan 1:  H1 = 64; H2 = 64; replay memory = 20K; ppong; paddle
constrained at top and bottom walls

Fri Dec 30 15:35:26 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 69760 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -40924

After 730 epochs, paddleX is flattened gaussian around X = 12 with small
bump at X = 24; eventual reward --> 0.0479 and very slowly rising; reward
--> 15.57 and rising; nframes/episode = 15758 and falling after having
peaked around 33K.  Very weak traces of ball tracks in 0th layer weights;
smooth evolution of weight dists; movement in weight values;

RL agent beats AI 20 to 9 in screen exports 02000 !!!
Agent beats AI 20 to 1 in screen exports 2500
Agent beats AI 20 to 4 in screen exports 2750

After 940 epochs, reward --> 14.5 and maybe asymptoting; nframes/episode =
18034; eventual reward --> 0.09 and slowly rising;

17.  Titan 1:  repeat expt 16; paddle constrained 

After 720 epochs, paddleX is gaussian aroujnd X = 12 with tiny bump at X =
24; reward --> 6.67 and rising; eventual reward --> 0.023 and very slowly
rising; nframes/episode --> 29181 and starting to level off

agent beats AI 20 to 10 in screen exports 2500

After 940 epochs, reward --> 0.05, eventual reward --> 0.046 and slowly
rising; nframes/episode --> 22860

18.  Titan 1:  H1 = 64; H2 = 128; replay memory = 20K; ppong; paddle
constrained at top and bottom walls

Fri Dec 30 15:38:09 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 2
   n_weights = 73984 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -41088

After 720 epochs, reward --> 10.58 and generally rising; nframes/episode =
18333 and falling after having peaked around 30K; eventual reward = 0.0639
and slowly rising; paddleX is gaussian around X = 13 with small step at X =
24; very faint traces of ball tracks in 0th layer weights; gradual
evolution of weight dists; movement in weight values;

agent beats AI 20 to 16 in screen exports 2000
agent beats AI 20 to 5 in screen exports 2250
agent beats AI 20 to 7 in screen exports 3000

After 908 epochs, reward --> 17.4; eventual reward --> 0.119;
nframes/episode --> 12810

19.  Titan 1:  repeat expt 18; paddle constrained at top and bottom walls

After 700 epochs, reward --> 9.12 and rising; nframes/episode --> 22938 and
falling after having peaked around 31K; eventual reward -> 0.0036 and
slowly rising; paddleX is distorted gaussian around X = 10 with small bump
at X = 24; OK weight dists and values;

agent beats AI 20 to 16 in screen exports 2000
agent beats AI 20 to 3 in screen exports 2250
agent beats AI 20 to 2 in screen exports 2500 but loses in 2750 

After 904 epochs, reward --> 10.05; nframes/episode --> 21583; eventual
reward --> 0.102 and slowly rising

30.  Titan 1:  H1 = 64, H2 = 64; replay mem = 20K ; ppong with 
no constraint on paddle position

Sat Dec 31 10:00:08 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 69760 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7207
Process ID = 5741

After 1200 epochs, results are no better than those for H1 = 32, H2 = 64
with no paddle constraints

31.  Titan 1:  repeat expt 30

Sat Dec 31 10:01:12 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 69760 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7269
Process ID = 5923

After 1250 epochs, results are qualitatively similar to those for H1 = 32,
H2 = 64 with no paddle constraints

40.  Titan 1:  H1 = 32; H2 = 128; replay memory = 20K; ppong
with no constraints; n_actions = 2

Sat Dec 31 10:30:21 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 2
   n_weights = 37120 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -9020
Process ID = 14209

After 2000 epochs, results are qualitatively similar to those for H1 = 32,
H2 = 64 with no paddle constraints

41.  Titan 1:  repeat expt 40

Sat Dec 31 10:31:04 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 2
   n_weights = 37120 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -9063
Process ID = 14493

After 2000 epochs, results are qualitatively similar to those for H1 = 32,
H2 = 64 with no paddle constraints




20.  Titan 3:  H1 = 64; H2 = 0; replay memory = 20K; qpong

Fri Dec 30 16:19:09 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 2
   n_weights = 65664 (FC)
base_learning_rate = 0.001; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 200000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.99
minimum epsilon = 0.1
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Old weights period = 2 epochs
Discard zero reward frac = 0
Use big states flag = 0
Frame skip = 1
1 big state = n_screen_states = 1
  Compute difference flag = 1
  Compute max flag = 0
Starting epoch for linear epsilon decay = 4
Stopping epoch for linear epsilon decay = 300
nn_update_frame_period = 1
nframes / epoch = 50000
n_max_epochs = 2000

After 24 epochs, eps = 0.95; no learning so far;

21.  Titan 3:  repeat expt 20
After 24 epochs, qualitatively similar results as for expt 20.

22.  Titan 1:  H1 = 128; H2 = 0; replay memory = 20K; qpong
Fri Dec 30 16:22:21 2016
Neural net params:
   n_layers = 3
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 128
   layer = 2 n_nodes = 2
   n_weights = 131328 (FC)
base_learning_rate = 0.001; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 200000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.99
minimum epsilon = 0.1
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Old weights period = 2 epochs
Discard zero reward frac = 0
Use big states flag = 0
Frame skip = 1
1 big state = n_screen_states = 1
  Compute difference flag = 1
  Compute max flag = 0
Starting epoch for linear epsilon decay = 4
Stopping epoch for linear epsilon decay = 300
nn_update_frame_period = 1
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -43739

After 13 epochs, eps = 0.95.  No learning.

23.  Titan 1:  H1 = 128; H2 = 0; replay memory = 20K; qpong
repeat expt 22

After 13 epochs, eps = 0.95.  No learning.


24.  TM:  H1 = 64; H2 = 32; replay memory 20K; qpong

Fri Dec 30 16:23:29 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 67648 (FC)
base_learning_rate = 0.001; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 200000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.99
minimum epsilon = 0.1
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Old weights period = 2 epochs
Discard zero reward frac = 0
Use big states flag = 0
Frame skip = 1
1 big state = n_screen_states = 1
  Compute difference flag = 1
  Compute max flag = 0
Starting epoch for linear epsilon decay = 4
Stopping epoch for linear epsilon decay = 300
nn_update_frame_period = 1
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -43806

After 40 epochs, eps -> 0.9; no learning in frames/episode or reward;
mostly flat dist for paddle_X;  some signs of ball tracks in 0th layer
weights; odd behavior for weight dists; odd behavior for weight values;

25.  TM:  repeat expt 24



28.  Titan 3:  H1 = 64, H2 = 32; replay mem = 20K ; ppong with 
no constraint on paddle position

Sat Dec 31 09:57:29 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 67648 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7046
Process ID = 29281

After 824 epochs, reward = 5.03 and rising; nframes/episode = 25121 and
falling; eventual reward = 0.014 and slowly rising;

29.  Titan 3:  repeat expt 28

Sat Dec 31 09:58:20 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 2
   n_weights = 67648 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7098
Process ID = 29295

After 851 epochs, reward = -8.85 and slowly rising; nframes/episode = 26149
and maybe slowly rising; eventual reward = -0.038 and maybe very slowly
rising;



34.  TM:  H1 = 64, H2 = 64; replay mem = 20K ; ppong with 
no constraint on paddle position; 3 actions including no op

Sat Dec 31 10:06:36 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 69824 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7594
Process ID = 24021

Reward locked at -21 after less than 100 epochs!


26.  Titan 3:  H1 = 64, H2 = 128; replay mem = 20K ; ppong with 
no constraint on paddle position

Sat Dec 31 09:48:22 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 2
   n_weights = 73984 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -6501
Process ID = 26135

After 758 epochs, reard = 13.55 nframes/episode = 20988 and falling; paddle
Y dist is guassian about X = 11 with small bump at X = 24; eventual reward
= 0.069 and steadily rising; OK weight dists and values; no strong ball
tracks in 0th layer weights;

Agent beats AI 20 to 17 in screen exports 2000; some good volleys!

Agent beats AI 20 to 6 in screen exports 2400; agent wins because of AI
bug;  but its play is not stupid


27.  Titan 3:  repeat expt 26

Sat Dec 31 09:49:46 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 2
   n_weights = 73984 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -6584
Process ID = 26458

After 769 epochs, reward = 13.4 and maybe increasing; nframes/episode =
17679 and falling; eventual reward = 0.0669 and slowly rising; paddle Y
dist is spiked gaussian at X = 10 with small bump at X = 24

38.  Titan 3:  H1 = 32; H2 = 64; 20K replay memory; ppong with no constraints;
2 actions

Sat Dec 31 10:25:30 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -8705
Process ID = 4484

After 1681 epochs, reward = 16.6 and probably plateauing; nframes/episode =
15034 and falling; eventual reward = 0.110 and steadily rising; paddle Y is
gaussian about X = 12 with tiny shoulder at X = 23; OK weight dists and
values; hard to see ball tracks in 0th layer weights

Agent loses to AI 4 to 20 in screen exports 2000
Agent loses to AI 20 to 11 in screen exports 2600

Agent beats AI 20 to 13 in screen exports 2800; 25.7K frames
                                                several good volleys
						most interesting for movie!

Agent beats AI 20 to 11 in screen exports 3000; 17.9K frames
Agent beats AI 20 to 1 in screen exports 5200; exploits AI bug

39.  Titan 3:  repeat expt 38

Sat Dec 31 10:27:11 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -8828
Process ID = 5324

After 1653 epochs, reward = 18.5 and plateaued; nframes/episode = 10833 and
plateaued; eventual reward = 0.18 and slowly rising; paddle Y is spiked
gaussian about X = 9 with small bump at X = 23; OK weight dists and values;
hard to see ball tracks in 0th layer weights

Agent loses to AI 11 to 20 in screen exports 2000
Agent loses to AI 19 to 20 in screen exports 2200  38.3K frames
Agent beats AI 20 to 14 in screen exports 2400     26.6K frames  
                                                     only wins from AI defect
Agent beats AI 20 to 11 in screen exports 2600     21.3K frames
                                                     more interesting play,
                                                     but first 7 wins are
						     due to defect
Agent beats AI 20 to 9 in screen exports 2800      20.6K frames
Agent beats AI 20 to 6 in screen exports 3000
Agent beats AI 20 to 3 in screen exports 4000
Agent beats AI 20 to 1 in screen exports 5000
Agent beats AI 20 to 2 in screen exports 6000


32.  TM:  H1 = 64, H2 = 128; replay mem = 20K ; ppong with 
no constraint on paddle position; 3 actions including no op

Sat Dec 31 10:05:04 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 3
   n_weights = 74112 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7503
Process ID = 23201

After 1014 epochs, reward = 6.05 and increasing; nframes/episode = 30457
and perhaps decreasing; eventual reward = -0.013 and slowly rising; very
faint traces of ball tracks in 0th layer weights; OK weight dists and values;

Agent beats AI 20 to 13 in screen exports 3000; extensive jitter in agent
paddle

33.  TM:  repeat expt 32

Sat Dec 31 10:05:34 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 3
   n_weights = 74112 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7532
Process ID = 23220

After 992 epoehcs, reward = 9.26 and increasing; nframes/episode = 19643
and falling; eventual reward = 0.0095 and slowly rising;

35.  TM:  Repeat expt 34

Sat Dec 31 10:06:41 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 69824 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7600
Process ID = 24026

After 1068 epochs, reward = -9.16 and slowly climbing; nframes/episode =
31321 and slowly rising; eventual reward = -0.025 and slowly rising

36.  TM:  H1 = 64, H2 = 32; replay mem = 20K ; ppong with 
no constraint on paddle position; 3 actions including no op

Sat Dec 31 10:08:16 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 3
   n_weights = 67680 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7693
Process ID = 25019

After 1065 epochs, reward = 3.68 and rising; nframes/episode = 38973 and
maybe has reached plateau; Both reward and nframes/episode were locked
at their minimal values for first 600 epochs!  eventual reward = 0.0029 and
slowly rising;

37.  TM:  H1 = 64, H2 = 32; replay mem = 20K ; ppong with 
no constraint on paddle position; 3 actions including no op

Sat Dec 31 10:08:20 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 3
   n_weights = 67680 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -7698
Process ID = 25022

After 1100 epochs, reward = 2.62 and generally rising; nframes/episode
= 31480 and generally falling; eventaul reward = 0.0304 and slowly rising;


42.  TM:  H1 = 32, H2 = 64; replay mem = 20K ; ppong with 
no constraint on paddle position; 3 actions including no op

Sat Dec 31 10:31:39 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -9097
Process ID = 32182

After 1702 epochs, reward = 11.43 and generally rising; nframes/episode =
18246 and falling; eventual reward = 0.101 and rising; OK weight dists and
values; no meaningful signals in 0th layer weights; paddle_y dist is
gaussian with spike at X = 10 plus small bump at X = 24;
Jerky movements with no benefit from no-op action

Agent beats AI 20 to 18 in screen exports 5000; agent plays rather stupidly
Agent beats AI 20 to 9 in screen exports 6200; agent plays quite stupidly!


43.  TM:  H1 = 32, H2 = 64; replay mem = 20K ; ppong with 
no constraint on paddle position; 3 actions including no op

Sat Dec 31 10:32:11 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -9130
Process ID = 32307

After 1710 epochs, reward = 15.6 and has generally plateaued;
nframes/episode = 15219 and has probably plateaued; eventual reward = 0.106
and is perhaps barely rising; paddle Y is gaussian with spike at X = 10 and
small bump at X = 24;

Agent beats AI 20 to 9 in screen exports 06200; wins exclusively from AI bug

44. Titan 1:  H1 = 32, H2 = 128; no paddle constraints; n_actions = 3

Sat Dec 31 20:07:34 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 3
   n_weights = 37248 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -43652
Process ID = 16019

After 1600 epochs, results are qualitatively similar to those for H1 = 32,
H2 = 64 with no paddle constraints and n_actions = 2

45. Titan 1:  H1 = 32, H2 = 128; no paddle constraints; n_actions = 3

Sat Dec 31 20:08:39 2016
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 128
   layer = 3 n_nodes = 3
   n_weights = 37248 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -43717
Process ID = 16481


46.  max mean KL divergence = 1E-4

Mon Jan  2 14:45:39 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 0.0001
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -97128
Process ID = 26733

KL divergence constraint appears to drastically slow down learning

47.  max mean KL divergence = 1E-4

Mon Jan  2 14:45:44 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 0.0001
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -97143
Process ID = 27104

KL divergence constraint appears to drastically slow down learning

49.  Titan 3: Anneal low pass filtering coeffs, disable KL divergence
constraint on learning

Tue Jan  3 08:30:24 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -61023
Process ID = 10853

Total failure!

50.  Titan 3: Anneal low pass filtering coeffs, disable KL divergence
constraint on learning
Tue Jan  3 08:30:28 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -61027
Process ID = 10861

Total failure!

51.  Titan 3: Anneal low pass filtering coeffs, disable KL divergence
constraint on learning

Tue Jan  3 08:30:33 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -61031
Process ID = 10869

Total failure!


52.  Sanity check:  no KL constraint; no low pass filtering; n_actions = 3

Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -67841
Process ID = 21081

Results after 580 epochs look reasonable.  After 2400 episodes, loss
function magnitude decreases slowly.  All metrics look good
including Y paddle distribution.

53.  Sanity check:  no KL constraint; no low pass filtering

Tue Jan  3 10:24:07 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -67846
Process ID = 21212

Results after 560 epochs look reasonable.  After 2400 episodes, metrics are
OK but not as nice as those for expt 52.


54.  Titan 3: Anneal low pass filtering coeffs, disable KL divergence
constraint on learning; n_actions = 2

Tue Jan  3 15:11:54 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -85114
Process ID = 4125

Disaster strikes around epoch 400 when low pass filtering begins!

55.  Titan 3: Anneal low pass filtering coeffs, disable KL divergence
constraint on learning; n_actions = 2

Tue Jan  3 15:12:24 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -85144
Process ID = 4147

Disaster strikes around epoch 400 when low pass filtering begins!

56.  Titan 3: Anneal low pass filtering coeffs, disable KL divergence
constraint on learning; n_actions = 2

Tue Jan  3 15:13:32 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 3000
Random seed = -85210
Process ID = 4834

Disaster strikes around epoch 400 when low pass filtering begins!


57.  Xavier init includes sqrt(2); generate episodes vs epochs plot

Wed Jan  4 07:54:09 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45246
Process ID = 7575

Basic results look OK.  But epoch indep var is messed up

58.  Xavier init includes sqrt(2); generate episodes vs epochs plot

Wed Jan  4 07:54:20 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45258
Process ID = 7584

Basic results look OK.  But epoch indep var is messed up

59.  Xavier init includes sqrt(2); generate episodes vs epochs plot

Wed Jan  4 07:54:24 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45263
Process ID = 7592

Basic results look OK.  But epoch indep var is messed up

60.  Xavier init includes sqrt(2); generate episodes vs epochs plot

Wed Jan  4 07:55:55 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45353
Process ID = 8779

Basic results look OK.  But epoch indep var is messed up

61.  max n_epochs = 4000; Xavier init includes sqrt(2); generate episodes
vs epochs plot

Wed Jan  4 14:59:29 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 4000
Random seed = -70767
Process ID = 19366

62.  max n_epochs = 4000; Xavier init includes sqrt(2); generate episodes
vs epochs plot
Wed Jan  4 14:59:37 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 4000
Random seed = -70774
Process ID = 19374

63.  max n_epochs = 4000; Xavier init includes sqrt(2); generate episodes
vs epochs plot

Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 4000
Random seed = -70850
Process ID = 19857

64.  max n_epochs = 4000; Xavier init includes sqrt(2); generate episodes
vs epochs plot

Wed Jan  4 15:01:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 4000
Random seed = -70869
Process ID = 20086


65.  TM:  Corrected epoch plots; n_actions = 2; Xavier init includes sqrt(2)

Thu Jan  5 06:30:01 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -26599
Process ID = 26928

66.  TM:  Corrected epoch plots; n_actions = 2; Xavier init includes sqrt(2)

Thu Jan  5 06:31:11 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -26669


67.  Corrected epoch plots; n_actions = 2; Xavier init includes sqrt(2)
0 accel penalty

Thu Jan  5 06:47:20 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -27638
Process ID = 1450

Metrics look good after 900 epochs; metrics look good after 2000 epochs.
Finished.

68.  Corrected epoch plots; n_actions = 2; Xavier init includes sqrt(2)
0 accel penalty

Thu Jan  5 06:47:23 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -27642
Process ID = 1458

Metrics look good after 900 epochs; metrics look good (modulo one big dip)
after 2K epochs.  Finished.

69.  Corrected epoch plots; n_actions = 3; Xavier init includes sqrt(2)
0 accel penalty

Thu Jan  5 06:49:06 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -27744
Process ID = 4827

Metrics look OK after 900 epochs; metrics look OK after 2K epochs.  Finished.

70.  T3: Corrected epoch plots; n_actions = 3; Xavier init includes sqrt(2)
0 accel penalty

Thu Jan  5 06:49:28 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -27766
Process ID = 4907

Metrics are maybe OK after 900 epochs; metrics look quite good after 2K
epochs.  Finished.


TM:  72.  0 accel penalty; corrected epoch plots; n_actions = 3;
Xavier init includes sqrt(2)

Thu Jan  5 07:17:43 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -29461
Process ID = 43009

73.  TM:  0 accel penalty; corrected epoch plots; n_actions = 3;
Xavier init includes sqrt(2)
Thu Jan  5 07:30:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -30208
Process ID = 2141


75.  T1:  1E-3 accel penalty; corrected epoch plots; n_actions = 3; 

Xavier init includes sqrt(2)

Thu Jan  5 12:36:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.0
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48568
Process ID = 18912

Metrics look OK after 250 epochs; Metrics look surprising good after 1400
epochs!  Agent beats AI 21 to 15 in screen_exports 3000 with minimal paddle
movement!  Some good, long rallies (which agent loses) near beginning of
screen exports 3000

screen_exports_3200:

Start excerpt at frame 818  (AI = 0, agent = 2); end excerpt at frame 3390
(AI = 1, agent = 5); play move skipping odd frames.  

AI = 5, agent = 15 is a also a good rally (wins)

76.  T1:  1E-3 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2)

Thu Jan  5 12:37:02 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48617
Process ID = 19401

Metrics do NOT look good after 240 epochs.  Very bad results after 1400
epochs.  


77.  T1:  3E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2)
Thu Jan  5 12:38:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48687
Process ID = 21103

Metrics look OK after 240 epochs;  metrics look quite good after nearly
1500 epochs.   Results qualitatively similar to those for expt 75.

78.  T1:  3E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2)

Thu Jan  5 12:38:46 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48723
Process ID = 22043

Metrics do NOT look good after 240 epochs.  Metrics are lousy after 


79.  TM:  0 accel penalty; corrected epoch plots; n_actions = 2;
Xavier init includes sqrt(2)
Thu Jan  5 08:12:55 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -32773
Process ID = 22239

metrics look good after 560 epochs; metrics look good after 1600 epochs

80.  TM:  0 accel penalty; corrected epoch plots; n_actions = 2;
Xavier init includes sqrt(2)

Thu Jan  5 08:12:59 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -32778
Process ID = 22242

metrics look OK after 560 epochs; metrics look good after 1600 epochs


81.  Corrected epoch plots w/ interp; n_actions = 2; 
Xavier init includes sqrt(2); 0 accel penalty

Thu Jan  5 12:00:50 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -46447
Process ID = 11394

Metrics look decent after 260 epochs (though lin interp is probably hurting
more than helping);  metrics OK after 1400 epochs

82.  Corrected epoch plots w/ interp; n_actions = 2; 
Xavier init includes sqrt(2); 0 accel penalty

Thu Jan  5 12:01:36 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -46492
Process ID = 11706

Metrics look OK after 260 epochs; metrics look good after 1400 epochs

83.  Corrected epoch plots w/ interp; n_actions = 3;
Xavier init includes sqrt(2); 0 accel penalty
flylab03:expt083% cat params.dat 
Thu Jan  5 12:03:20 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -46598
Process ID = 14747

Metrics look OK after 260 epochs; metrics slowly improving around 1400 epochs

84.  Corrected epoch plots w/ interp; n_actions = 3;
Xavier init includes sqrt(2); 0 accel penalty

Thu Jan  5 12:04:15 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -46652
Process ID = 15186

Metrics look OK after 260 epochs; metrics slowly improving around 1400 epochs


85.  3E-3 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots

Thu Jan  5 12:40:02 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48797
Process ID = 24400

86.  3E-3 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots

Thu Jan  5 12:40:05 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48804
Process ID = 24619


87.  1E-2 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots
Thu Jan  5 12:41:34 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.01
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48892
Process ID = 27206

88.  1E-2 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots
Thu Jan  5 12:41:38 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.01
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -48896
Process ID = 27217

89.  T1:  1E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots 1400 epochs.

Thu Jan  5 13:34:18 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -52057
Process ID = 975

Metrics look OK after 160 epochs;  Metrics look good after 1400 epochs.
Lots of jitter in game play.


90.  T1:  1E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots

Thu Jan  5 13:34:23 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -52061
Process ID = 1049

Metrics look OK after 160 epochs; metrics slowly improving after 1400
epochs.  Lots of jitter in game play.

91.  T1: 3E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots

Thu Jan  5 14:15:37 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -54536
Process ID = 19872

Metrics look OK after 110 epochs; metrics look quite at end of 2K epochs.
Less jitter than for 0 accel case.  But more jitter than for expts 75 and
77.  Finished.


92.  T1:  3E-4 accel penalty; corrected epoch plots; n_actions = 3; 
Xavier init includes sqrt(2); interp corrected epoch plots

Thu Jan  5 14:15:40 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -54539
Process ID = 19944

Metrics look OK after 110 epochs; Very good metrics after 1400 epochs
Accidentally deleted all track files :( Agent crushes opponent in screen
exports 7800 with very little paddle movement!  Finished after 2K epochs.


93.  TM:  0 accel penalty; n_actions = 2; corrected epoch plots; 
mu/sigma for accel mag

Thu Jan  5 15:55:46 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -60544
Process ID = 11807

metrics look good after 1000 epochs; jaggy curves

94.  TM:  0 accel penalty; n_actions = 2; corrected epoch plots; n_actions = 2;
mu/sigma for accel mag

Thu Jan  5 15:55:54 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 2
   n_weights = 34944 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 2
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -60553
Process ID = 11855

metrics look good after 960 epochs; jaggy curves


95.  TM:  3E-4 accel penalty; n_actions = 3; corrected epoch plots; 
mu/sigma for accel mag

Thu Jan  5 15:59:32 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -60770
Process ID = 15598

metrics look good after 1000 epochs; pong play is only barely less jerky
than case with no acceleration constraint

96.  TM:  3E-4 accel penalty; n_actions = 3; corrected epoch plots; 
mu/sigma for accel mag

Thu Jan  5 15:59:36 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -60775
Process ID = 15599

metrics look good after 1000 epochs; lots of jitter in game play


*********  Movie of RL agent beating AL with no paddle movement ********

97.  TM:  1E-3 accel penalty; n_actions = 3; corrected epoch plots; 
mu/sigma for accel mag

Thu Jan  5 16:02:09 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -60928
Process ID = 17176

Agent learned that it can move to a particular location and stand still and
beat AI 21 to 0!  See screen exports 06200.  But this same strategy can
also cause it to lose 20 to 1.  Generally bad metrics.  But we should
definitely mention this case in the writeup!

98.  TM:  1E-3 accel penalty; n_actions = 3; corrected epoch plots; 
mu/sigma for accel mag

Thu Jan  5 16:02:17 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -60936
Process ID = 17292

Generally bad metrics.  


102. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Fri Jan  6 07:41:23 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -17279
Process ID = 21200

Metrics look reasonable after 400 epochs After 1750+ epochs, averaged
reward is only around 0.  Mediocre play performance.  TERMINATED.


104.  T1.  n_actions = 3; accel penalty = 3E-4; fixed X>Y curve writing 

Fri Jan  6 12:13:14 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -33592
Process ID = 2812

Good metrics after 400 epochs.  But accel penalty of 3E-4 didn't prevent
jitter.

105.  T1.  n_actions = 3; accel penalty = 3E-4; fixed X>Y curve writing
Fri Jan  6 07:56:17 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -18175
Process ID = 6983

Good metrics after 400 epochs.  But accel penalty of 3E-4 didn't prevent
jitter.



106.  T1.  n_actions = 3; accel penalty = 3E-4; fixed X>Y curve writing
Fri Jan  6 07:56:20 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -18178
Process ID = 7041

Good metrics after 400 epochs.  But accel penalty = 3E-4 didn't prevent
jitter.



117.  TM.  n_actions = 3; accel penalty = 1E-3; fixed X>Y curve writing
Fri Jan  6 15:26:10 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45167
Process ID = 4731

Bad metrics after 1000 epochs.  TERMINATED.

118.  TM.  n_actions = 3; accel penalty = 1E-3; fixed X>Y curve writing
Fri Jan  6 15:26:17 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45175
Process ID = 4743

Bad metrics after 1200 epochs.  TERMINATED.


-------------------------------------------------------------
RUNNING EXPERIMENTS
-------------------------------------------------------------

m6700
-----

Thinkmate
---------

109. TM:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Original job start at 8:45am killed due to lousy results after 200 epochs.

Fri Jan  6 11:47:31 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -31985
Process ID = 34088

110. TM:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Fri Jan  6 08:45:45 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -21144
Process ID = 21829

Metrics look reasonable after 200 epochs

113.  T1.  n_actions = 3; accel penalty = 1E-3; fixed X>Y curve writing
Job 1 killed after 100 epochs due to lousy metrics.
Job 2 killed after 100 epochs due to lousy metrics.

Fri Jan  6 15:22:38 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -44953
Process ID = 30685

Lousy metrics.  TERMINATED


Titan 1:
-------

103.  T1.  n_actions = 3; accel penalty = 3E-4; fixed X>Y curve writing
Job 1 killed after 400 epochs due to lousy metrics.  

Fri Jan  6 12:11:16 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.0003
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -33452
Process ID = 2084

114.  T1.  n_actions = 3; accel penalty = 1E-3; fixed X>Y curve writing
Job 1 killed after 200 epochs due to poor metrics
Fri Jan  6 15:23:45 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45023
Process ID = 31632

After 2K epochs, agent learns to nearly remain stationary at golden
location.

*********  Movie of RL agent beating AL with minimal paddle movement ********

115.  T1.  n_actions = 3; accel penalty = 1E-3; fixed X>Y curve writing
Job 1 killed after 280 epochs due to lousy metrics

Fri Jan  6 15:24:58 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -45097
Process ID = 322

Work with screen_05000
Note: Episode 5000 = epoch 920.429

Movie excerpt:  Start at frame 16168 when agent leads AI by 18 to 9



116.  T1.  n_actions = 3; accel penalty = 1E-3; fixed X>Y curve writing
Fri Jan  6 12:21:37 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0.001
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -34096
Process ID = 10133

Titan 3:
-------

99. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing

(Job 1 killed and restarted when first attempt yielded poor results around
epoch 100; job 2 killed and restearted when 2nd attempt yielded lousy results)

Fri Jan  6 11:50:26 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -32224
Process ID = 13901

100. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing

Fri Jan  6 07:38:45 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -17124
Process ID = 19491

Metrics after 400 epochs look reasonable.

101. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Job1 with mediocre metrics after 400 epochs killed and restarted.

Fri Jan  6 11:52:49 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -32359
Process ID = 14967

107. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Fri Jan  6 08:07:45 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -18863
Process ID = 13615

Metrics look reasonable after 350 epochs

108. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Fri Jan  6 08:07:48 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -18867
Process ID = 13625

Metrics look reasonable after 350 epochs

111. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing


Fri Jan  6 13:50:55 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -39438
Process ID = 25715

*********  Movie of RL agent beating AL with jittery paddle movement ********

112. T3:  n_actions = 3; accel penalty = 0; fixed X>Y curve writing
Fri Jan  6 11:59:15 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 1024
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 3
   n_weights = 35008 (FC)
base_learning_rate = 0.001; batch_size = -1
P learning
max mean KL divergence between pi(curr) and pi(next) = 1e+08
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 20000
Number random samples drawn from replay memory Nd = -999
Discount factor gamma = 0.99
minimum epsilon = -nan
n_actions = 3
Leaky ReLU small slope = 0.01
Learning rate decrease period = 10000 episodes
Delayed accel penalty = 0
nframes / epoch = 50000
n_max_epochs = 2000
Random seed = -32753
Process ID = 18416

Metrics look quite good after 1500 epochs.  

Screen exports:

  3000:  Agent loses to AI 9 to 20
  3200:  Agent loses to AI 16 to 20
  3400:  Agent loses to AI 18 to 20
  3600   Agent beats AI 21 to 20
  3800:  Agent beats AI 20 to 8
  4000:  Agent beats AI 20 to 4
  4400   Agent beats AI 20 to 5
  4200   Agent beats AI 20 to 5
  4600:  Agent beats AI 20 to 8

Movie excerpt for screen exports 3600:  
Note:  Episode 3600 = epoch 845.868

Start around frame 25243 when agent trails AI 17 to 19.  Skip odd frames.
Movie clip lasts approx 30 secs

Start at frame 24021 when agent trails AI 17 to 18.  Skip = 1 frame.  .

Increase skip to 2 frames around frame 25966 when agent trails AI 18 to 19.

Pause movie at last frame for approx 10 secs before stopping recording.

Movie clip then lasts for 1 minute.

===========================================================
Conclusions from 18 expt runs on Fri Dec 30:

  *.  Ppong with H1 = 64; H2 = 128; replay memory = 20K crushes
      AI after 720 epochs.

Conclusions from >20 expt runs on Sat, Dec 31:

  *.  Ppong with H1 = 32, H2 = 64; replay memory = 20K, n_actions = 2 and NO
      artificial top/bottom wall constraints on paddle movement yields
      very good cumulative reward and nframes/episode results

  *.  Ppong with n_actions = 3 exhibits no less jerkiness than n_actions =
      2.  Almost certainly will need to modify loss function to penalize
      accelerations before jerkiness will decrease.


Conclusion:  1E-2 accel penalty is much too large (for discrete accel
expression a propto y(t+1) - 2 y(t) + y (t-1).

Conclusion:  3E-3 accel penalty is very likely too large (for discrete accel
expression a propto y(t+1) - 2 y(t) + y (t-1).

Conclusion:  1E-4 accel penalty it too small to prevent jitter
             3E-4 and 1E-3 can sometimes yield very good results with little
             jitter.  But they can also sometime yield terrible game play.

===========================================================
TODO:

A.  Implement weight normalization 

B.  Implement data-dependent weight initialization

C.  Experiment with trying to extract ball and paddle posn and velocity and
forming much smaller input layer for a much smaller neural net


DONE:

A.  Fix memory leak!

B.  Revert to working with difference state rather than 1 big state
containing 2 screen states

C.  Fix exporting of each individual screen rather than every 3rd or 4th
one

G.  Trace individual weights' evolutions

F.  Perhaps experiment with 3 hidden layer neural network but only after
implementing batch normalization 

