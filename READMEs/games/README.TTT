==========================================================================
Deep Q learning notes for TTT
==========================================================================
Last updated on 1/13/17
==========================================================================

Best results so far


Experiment 15
Fri Jan 13 06:54:47 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -19286
Process ID = 29236

Base learning rate too small
win frac = 0.666
cum reward --> 0.808

------------------------------------------------------
TERMINATED EXPERIMENTS
------------------------------------------------------

10.  T1: Opponent plays randomly: H1 = H2 = 32; blr = 1E-6

Experiment 10
Fri Jan 13 06:49:53 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -18991
Process ID = 20517

Base learning rate too small
win frac = 0.632
cum reward --> 0.713

11.  T1: Repeat expt 10

Experiment 11
Fri Jan 13 06:50:41 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -19038
Process ID = 21086

Base learning rate too small
win frac = 0.642
cum reward --> 0.727

12.  T1: Opponent plays randomly: H1 = 16; H2 = 32; blr = 1E-6

Experiment 12
Fri Jan 13 06:52:19 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 3584 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -19137
Process ID = 23821

Base learning rate too small
win frac = 0.670
cum reward --> 0.813

13.  T1: Repeat expt 12

Experiment 13
Fri Jan 13 06:53:09 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 3584 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -19187
Process ID = 25111

Base learning rate too small
win frac = 0.647
cum reward --> 0.823

14.  T1: Opponent plays randomly: H1 = 16; H2 = 16; blr = 1E-6

Experiment 14
Fri Jan 13 06:54:35 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -19272
Process ID = 28729

Base learning rate too small
win frac = 0.631
cum reward --> 0.654

15.  T1: Repeat expt 14

Experiment 15
Fri Jan 13 06:54:47 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -19286
Process ID = 29236

Base learning rate too small
win frac = 0.666
cum reward --> 0.808

20.  T1:  Opponent plays randomly: H1 = H2 = 16; blr = 1E-5

Experiment 20
Fri Jan 13 07:54:28 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-05; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -22867
Process ID = 11404

Base learning rate too large


21.  T1:  Opponent plays randomly: H1 = H2 = 16; blr = 1E-5

Experiment 21
Fri Jan 13 07:55:09 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-05; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -22908
Process ID = 11979

Base learning rate too large

22.  T1:  Opponent plays randomly: H1 = H2 = 16; blr = 3E-6

Experiment 22
Fri Jan 13 07:56:07 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 3e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -22966
Process ID = 14264

23.  T1:  Opponent plays randomly: H1 = H2 = 16; blr = 3E-6

Experiment 23
Fri Jan 13 07:56:09 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 3e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -22969
Process ID = 14381


24.  T1:  Opponent plays randomly:  H1 = H2 = 16; blr = 5E-6

Experiment 24
Fri Jan 13 08:08:36 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 5e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -23715
Process ID = 30184

25.  T1:  Opponent plays randomly:  H1 = H2 = 16; blr = 5E-6

Experiment 25
Fri Jan 13 08:08:39 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 5e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 5000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -23718
Process ID = 30216

16.  T3: Opponent plays randomly: H1 = H2 = 32; blr = 5E-6

Experiment 16
Fri Jan 13 08:17:03 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 5e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -24222
Process ID = 2794

17.  T3: Opponent plays randomly: H1 = H2 = 32; blr = 5E-6

Experiment 17
Fri Jan 13 08:17:06 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 5e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -24225
Process ID = 2802

18.  T3: Opponent plays randomly: H1 = H2 = 32; blr = 3E-6

Experiment 18
Fri Jan 13 08:18:42 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 3e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -24321
Process ID = 5621

19.  T3: Opponent plays randomly: H1 = H2 = 32; blr = 3E-6

Experiment 19
Fri Jan 13 08:18:46 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 3e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -24324
Process ID = 5801


26.  T1: Opponent plays randomly: H1 = H2 = 16; blr = 2E-6
Experiment 26
Fri Jan 13 10:07:40 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 2e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -30858
Process ID = 24208

27.  T1: Opponent plays randomly: H1 = H2 = 16; blr = 2E-6
Experiment 27
Fri Jan 13 10:07:43 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 2e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -30862
Process ID = 24216

28.  T1: Opponent plays randomly: H1 = H2 = 32; blr = 2E-6

Experiment 28
Fri Jan 13 10:08:43 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 2e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -30922
Process ID = 26685


29.  T1: Opponent plays randomly: H1 = H2 = 32; blr = 2E-6

Experiment 29
Fri Jan 13 10:08:46 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 2e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 264000
Random seed = -30925
Process ID = 26780

------------------------------------------------------
RUNNING EXPERIMENTS
------------------------------------------------------


---------------------
Thinkmate
---------------------


---------------------
Titan 1:
---------------------


30.  T1: Opponent plays randomly: H1 = H2 = 16; blr = 1E-6

Experiment 30
Fri Jan 13 11:59:27 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -37566
Process ID = 31422

31.  T1: Opponent plays randomly: H1 = H2 = 16; blr = 1E-6

Experiment 31
Fri Jan 13 11:59:30 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -37569
Process ID = 31430

32.  T1: Opponent plays randomly: H1 = H2 = 32; blr = 1E-6
Experiment 32
Fri Jan 13 12:01:22 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -37682
Process ID = 2503

33.  T1: Opponent plays randomly: H1 = H2 = 32; blr = 1E-6

Experiment 33
Fri Jan 13 12:01:26 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5120 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -37685
Process ID = 2633


---------------------
Titan 3:
---------------------

34.  T3:  Opponent plays random: H1 = H2 = 64; blr = 1E-6
Experiment 34
Fri Jan 13 12:07:31 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 64
   n_weights = 12288 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -38050
Process ID = 9338

35.  T3:  Opponent plays random: H1 = H2 = 64; blr = 1E-6
Experiment 35
Fri Jan 13 12:07:34 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 64
   layer = 2 n_nodes = 64
   layer = 3 n_nodes = 64
   n_weights = 12288 (FC)
base_learning_rate = 1e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -38053
Process ID = 9346

36.  T3:  Opponent plays random: H1 = H2 = 16; blr = 2E-6

Experiment 36
Fri Jan 13 12:10:54 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 2e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -38252
Process ID = 13153

37.  T3:  Opponent plays random: H1 = H2 = 16; blr = 2E-6

Experiment 37
Fri Jan 13 12:10:58 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 64
   layer = 1 n_nodes = 16
   layer = 2 n_nodes = 16
   layer = 3 n_nodes = 64
   n_weights = 2304 (FC)
base_learning_rate = 2e-06; batch_size = 1
Q learning
solver type = RMSPROP
   rmsprop_decay_rate = 0.9
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.01
Replay memory capacity = 10000
Number random samples drawn from replay memory Nd = 32
Discount factor gamma = 0.95
minimum epsilon = 0.1
n_actions = 64
Leaky ReLU small slope = 0.01
Learning rate decrease period = 200000 episodes
Old weights period = 5000 episodes
n_max_episodes = 200000
Frame skip = -1
Starting episode for linear epsilon decay = 1000
Stopping episode for linear epsilon decay = 132000
Random seed = -38257
Process ID = 13339


==========================================================================

Conclusion:  Base learning rate 1E-5 is too large.
Conclusion:  Base learning rate 5E-6 is too large.
Conclusion:  Base learning rate 3E-6 may be OK.
Conclusion:  Base learning rate 2E-6 is probably too large.

Conclusion:  Base learning rate 1E-6 is too small.

Conclusion:  Max Q percentile curves look better for H1=H2=32 than for
H1=H2=16



