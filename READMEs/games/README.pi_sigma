==========================================================================
Training pi_sigma for TTT
==========================================================================
Last updated on 1/16/17
==========================================================================

Best results so far:

------------------------------------------------------
TERMINATED EXPERIMENTS
------------------------------------------------------

5.  m6700

Experiment 5
Mon Jan 16 10:28:40 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 65
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5152 (FC)
base_learning_rate = 0.0001; batch_size = 32
solver type = RMSPROP
   rmsprop_decay_rate = 0.95
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.001
n_training_samples = 85135
n_test_samples = 9438
Max n_training_epochs = 1000
Leaky ReLU small slope = 0.01
Process ID = 5253

Bad loss behavior

10.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-4

Bad loss behavior

11.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 1E-4

Bad loss behavior

12.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-5

Bad loss behavior

13.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-4

Bad loss behavior

14.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 1E-4

Bad loss behavior

15.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-5

Bad loss behavior


16.  TM
H1 = 32, H2 = 32, H3 = 32
lambda = 1E-3
base_learning_rate = 3E-4

Bad loss behavior

17.  TM
H1 = 32, H2 = 32, H3 = 32
lambda = 1E-3
base_learning_rate = 1E-4

Bad loss behavior


18.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 1E-6

19.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-7

20.  T1
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 1E-6

27.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 0
base_learning_rate = 3E-5

21.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-7

22.  T3
H1 = 32, H2 = 32, H3 = 32
lambda = 1E-3
base_learning_rate = 1E-6

23.  T3
H1 = 32, H2 = 32, H3 = 32
lambda = 1E-3
base_learning_rate = 3E-7

28.  T1
H1 = 64, H2 = 64, H3 = 0
lambda = 0
base_learning_rate = 3E-5

24.  TM
H1 = 32, H2 = 32, H3 = 0
lambda = 0
base_learning_rate = 3E-5

25.  TM
H1 = 32, H2 = 32, H3 = 0
lambda = 0
base_learning_rate = 1E-4

26.  TM
H1 = 32, H2 = 32, H3 = 0
lambda = 0
base_learning_rate = 1E-5

30.  T1
max move rel to end = 1
H1 = H2 = 32
lambda = 0.01
base_learning_rate = 1E-

31.  T1
max move rel to end = 1
H1 = H2 = 32
lambda = 0.001
base_learning_rate = 3E-5

32.  T1
max move rel to end = 1
H1 = H2 = 32
lambda = 0.003
base_learning_rate = 3E-5

------------------------------------------------------
RUNNING EXPERIMENTS
------------------------------------------------------

---------------------
Titan 1:
---------------------

33.  T1
max move rel to end = 1
H1 = H2 = 32
lambda = 0.005
base_learning_rate = 1E-6

34.  T1
max move rel to end = 1
H1 = 64; H2 = 32
lambda = 0.005
base_learning_rate = 1E-6

35.  T1
max move rel to end = 1
H1 = 32; H2 = 32; H3 = 32
lambda = 0.005
base_learning_rate = 1E-6

---------------------
Titan 3:
---------------------

---------------------
Thinkmate
---------------------

---------------------
m6700
---------------------

6.  m6700
Experiment 6
Mon Jan 16 10:47:51 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 65
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5152 (FC)
base_learning_rate = 3e-05; batch_size = 32
solver type = RMSPROP
   rmsprop_decay_rate = 0.95
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.001
n_training_samples = 85135
n_test_samples = 9438
Max n_training_epochs = 1000
Leaky ReLU small slope = 0.01
Process ID = 7786


==========================================================================
Conclusions:

As of 1 pm on Mon Jan 16, 2017, it looks like base learning rate must be no
larger than 1E6 to avoid horrible loss divergence behavior, at least when
lambda = 1E-3.

