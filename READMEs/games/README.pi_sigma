==========================================================================
Training pi_sigma for TTT
==========================================================================
Last updated on 1/16/17
==========================================================================

Best results so far:


------------------------------------------------------
RUNNING EXPERIMENTS
------------------------------------------------------

---------------------
Titan 1:
---------------------

10.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-4

11.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 1E-4

12.  T1
H1 = 64, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-5

---------------------
Titan 3:
---------------------

13.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-4

14.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 1E-4

15.  T3
H1 = 32, H2 = 32, H3 = 0
lambda = 1E-3
base_learning_rate = 3E-5

---------------------
Thinkmate
---------------------

16.  TM
H1 = 32, H2 = 32, H3 = 32
lambda = 1E-3
base_learning_rate = 3E-4

17.  TM
H1 = 32, H2 = 32, H3 = 32
lambda = 1E-3
base_learning_rate = 1E-4


---------------------
m6700
---------------------

5.  m6700

Experiment 5
Mon Jan 16 10:28:40 2017
Neural net params:
   n_layers = 4
   layer = 0 n_nodes = 65
   layer = 1 n_nodes = 32
   layer = 2 n_nodes = 32
   layer = 3 n_nodes = 64
   n_weights = 5152 (FC)
base_learning_rate = 0.0001; batch_size = 32
solver type = RMSPROP
   rmsprop_decay_rate = 0.95
   rmsprop_denom_const = 1e-05
L2 regularization lambda coeff = 0.001
n_training_samples = 85135
n_test_samples = 9438
Max n_training_epochs = 1000
Leaky ReLU small slope = 0.01
Process ID = 5253

==========================================================================
Conclusion:

