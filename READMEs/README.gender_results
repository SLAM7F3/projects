==========================================================================
Gender detection results
==========================================================================
Last updated on 8/5/16; 8/6/16; 8/8/16; 8/9/16
==========================================================================

*.  On 7/31/16, we generated 17,457 = 9747 female + 7710 male image chips
from the Adience dataset which are 106x106 in pixel size.  They are sitting
in /macpro_4GB_disk/data/peter_stuff/imagery/faces/adiencefaces_106x106 on
Thinkmate.

*.  As of 7/31/16, we place female and male image chips into dated
subsubdirs of training/, validation/ and testing/ subdirs of
/macpro_4GB_disk/data/caffe/faces/image_chips/ on Thinkmate.  Training
image chips are 106x106 in pixel size, while validation & testing image
chips are 96x96 in pixel size.

Jul 30: 4 * 37817 = 151,268 training, 1037 validation & 3159 testing chips

Jul 31: 33172 training, 207 validation & 664 testing chips coming from
        Adience data 

Combined Jul30 + Jul31 face chip sets sitting in 

/data/caffe/faces/image_chips/training/Jul30_31_106x106/
/data/caffe/faces/image_chips/validation/Jul30_31_96x96/
/data/caffe/faces/image_chips/testing/Jul30_31_96x96/

 184,440 106x106 training, 1243 96x96 validation and 3822 96x96 testing chips

*.  As of 7/24/16, ID_strings for corrupted images which OSG cannot import:

ID_str = 00725
ID_str = 01054
ID_str = 02762
ID_str = 03257

We stopped labeling face genders on Sunday, 7/24/16/ using our
attribute_images tool.  Statistics as of 7/24/16 for our personally
attributed images:

ubuntu:images% imglab  --stats alfhi.xml
Number of images: 13740
Number of different labels: 2
Number of non-ignored boxes: 78688

Label: face
   number of images:      10492
   number of occurrences: 43752
   min box area:    1
   max box area:    2.95653e+06
   mean box area:   11387.6
   stddev box area: 50630.9
   mean width/height ratio:   0.787305
   stddev width/height ratio: 0.238317

Label: hand
   number of images:      8671
   number of occurrences: 34936
   min box area:    1
   max box area:    3.42514e+06
   mean box area:   5994.51
   stddev box area: 41698.8
   mean width/height ratio:   1.06864
   stddev width/height ratio: 0.524913

n_faces = 43730 n_unset_faces = 0 n_male_faces = 20961 n_female_faces = 21050 n_unknown_faces = 1719
unset_frac = 0 male_frac = 0.479328 female_frac = 0.481363 unknown_frac = 0.0393094

16933 female + 3937 = 20870 female
16498 male + 4453 skinny male = 20951 male


width_10 = 8.02151
width_20 = 13.0974
width_25 = 15.8397
width_30 = 18.715
width_40 = 24.7056
width_50 = 30.8453
width_60 = 38.583
width_70 = 50.1832
width_75 = 57.5868
width_80 = 67.3981
width_90 = 99.1431
n_images = 13740
Number of object bboxes = 43752

Face bbox aspect ratio:  median +/- quartile_width = 0.7447 +/- 0.1054

===============================================================

*.  Weds Jul 20, Titan 1

/data/TrainingImagery/faces/labeled_data/faces_13/
Wed Jul 20 13:38:00 2016

n_total_images =  13710
n_training_images = 11910
n_validation_images = 600
n_testing_images = 1200
istart = 0 istop = 11912
n_training_bboxes = 68108
n_validation_bboxes = 3271
n_testing_bboxes = 6979
Full object classification
  face
  hand
Use scaled training data flag = 1
Augmented data flag = 1
Tinting threshold = 0.2
RGB --> greyscale flag = 1
Noise threshold = 0.5
Ignore faces flag = 0
Ignore hands flag = 0
Visualize masks flag = 0
Number of tile samples per positive example #0 (face) bbox = 9
Number of tile samples per positive example #1 (hand) bbox = 4
Max tiles per image = 40

Number of exported training tiles = 280398
Number of exported validation tiles = 0
n_positive_example_tiles = 238682
n_negative_example_tiles = 41716

Finished training
/data/deeplab/faces_deploy/train_iter_40000_07202016_T1.caffemodel

*.  Weds July 20, Titan 3:

/data/TrainingImagery/faces/labeled_data/faces_13/
Wed Jul 20 15:13:08 2016

n_total_images =  13710
n_training_images = 11910
n_validation_images = 600
n_testing_images = 1200
istart = 0 istop = 11912
n_training_bboxes = 68108
n_validation_bboxes = 3271
n_testing_bboxes = 6979
Quadrant object classification
Use scaled training data flag = 1
Augmented data flag = 1
Tinting threshold = 0.2
RGB --> greyscale flag = 1
Noise threshold = 0.5
Ignore faces flag = 0
Ignore hands flag = 1
Visualize masks flag = 0
Number of tile samples per positive example #0 (face) bbox = 9
Number of tile samples per positive example #1 (hand) bbox = 0
Max tiles per image = 40

Number of exported training tiles = 236576
Number of exported validation tiles = 0
n_positive_example_tiles = 192014
n_negative_example_tiles = 44562

Finished training
/data/deeplab/faces_deploy/train_iter_40000_07202016_T3.caffemodel

Validation set of 600 images:

Decade 0 Bbox width: min=0 max=7	 Recall=0	 111 bboxes
Decade 1 Bbox width: min=7 max=12	 Recall=0	 150 bboxes
Decade 2 Bbox width: min=12 max=18	 Recall=0.295918	 190 bboxes
Decade 3 Bbox width: min=18 max=24	 Recall=0.598639	 166 bboxes
Decade 4 Bbox width: min=24 max=31	 Recall=0.738095	 183 bboxes
Decade 5 Bbox width: min=31 max=39	 Recall=0.792517	 179 bboxes
Decade 6 Bbox width: min=39 max=50	 Recall=0.84898	 174 bboxes
Decade 7 Bbox width: min=50 max=67	 Recall=0.82568	 167 bboxes
Decade 8 Bbox width: min=67 max=100	 Recall=0.846939	 190 bboxes
Decade 9 Bbox width: min=100 max=10000	 Recall=0.818594	 270 bboxes
Tiny bbox recall = 0 		 358 tiny bboxes
Small bbox recall = 0.680758 		 411 small bboxes
Medium bbox recall = 0.824068 		 472 medium bboxes
Large bbox recall = 0.837828 		 539 large bboxes
Total bbox recall = 0.744606 		 1780 total bboxes
Pixel precision = 0.839711
f_value = 2 * prec * recall / (prec + recall) = 0.789304

Testing set of 1200 images:

Decade 0 Bbox width: min=0 max=7	 Recall=0	 324 bboxes
Decade 1 Bbox width: min=7 max=12	 Recall=0	 399 bboxes
Decade 2 Bbox width: min=12 max=18	 Recall=0.0765306	 403 bboxes
Decade 3 Bbox width: min=18 max=24	 Recall=0.6678	 393 bboxes
Decade 4 Bbox width: min=24 max=31	 Recall=0.80758	 424 bboxes
Decade 5 Bbox width: min=31 max=39	 Recall=0.790816	 374 bboxes
Decade 6 Bbox width: min=39 max=50	 Recall=0.786565	 335 bboxes
Decade 7 Bbox width: min=50 max=67	 Recall=0.851648	 327 bboxes
Decade 8 Bbox width: min=67 max=100	 Recall=0.838346	 411 bboxes
Decade 9 Bbox width: min=100 max=10000	 Recall=0.799024	 507 bboxes
Tiny bbox recall = 0 		 939 tiny bboxes
Small bbox recall = 0.733909 		 953 small bboxes
Medium bbox recall = 0.806122 		 908 medium bboxes
Large bbox recall = 0.820228 		 1097 large bboxes
Total bbox recall = 0.698602 		 3897 total bboxes
Pixel precision = 0.828947
f_value = 2 * prec * recall / (prec + recall) = 0.758213




*.  Sat Jul 23, Titan 1

Gender classification, VGG network, baseline set of O(20K) female + O(20K)
male faces

Finished training
/data/caffe/faces/trained_models/Jul22_43K_vgg/train_iter_22126.caffemodel
Learning curve validation accuracy around 82.3%

*.  Sun Jul 24, Titan 1

Gender classification, VGG network, augmented set of O(4 * 20K) female +
O(4 * 20K) male faces

Started training on Titan 1 around 12:55 pm on Sun, Jul 24.  This model did
finish training, but we lost it!  At least we have its tuning performance
curves.  Learning curve validation accuracy around 84.5%

*.  Mon Jul 25, Titan 3, early afternoon

Gender classification, 6 layer face network following model of Levi and
Hassner in "Age and Gender Classification using Convolution Neural
Networks", baseline set of O(20K) female + O(20K) male faces

/data/caffe/faces/trained_models/Jul25_43K_face_6layers_T3/train_iter_13000.caffemodel
Learning curve validation accuracy around 69.3

*.  Mon Jul 25, Titan 1, early evening

Gender classification, 7 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.001

/data/caffe/faces/trained_models/Jul25_43K_face_7layers_T1/train_iter_31000.caffemodel
Learning curve validation accuracy around 61.8%

*.  Tues Jul 26, Titan 1, 6:10 am

Gender classification, 7 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.0003, accuracy
layer added for training phase, 512 nodes within fc layers

Training started around 6:15 am on Tues, July 26

*.  Tues Jul 26, Titan 3, 6:30 am

Gender classification, 7 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.0003, accuracy
layer added for training phase, 256 nodes within fc layers.

Training started around 6:30 am on Tues, July 26

We expect training for 10 epochs = 13K iterations should take around 6 hours

Note:  We abandoned both Tues early morning training sessions when we
realised these models had O(400M) params !

*.  Tues Jul 26, Titan 1, 8:10 am

Gender classification, 13 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.0003, accuracy
layer added for training phase

Network showed NO signs of training after 20+ epochs!
Perhaps learning rate is too high.  And maybe O(1M) weights is not enough.

*.  Tues Jul 26, Titan 3, 8:10 am

Gender classification, 13 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.001, accuracy
layer added for training phase

Ran out of disk space on Titan 3 !!!

*.  Tues Jul 26, Titan 1, 12 pm

Gender classification, 13 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.0001, accuracy
layer added for training phase

Increase number of weights per layer compared to 8 am test.  
Results around 5 pm are awful - no better than chance

*.  Tues Jul 26, Titan 3, 12 pm

Gender classification, 13 layer face network "mini VGG", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.001, accuracy
layer added for training phase

Increase number of weights per layer compared to 8 am test.  
Results around 5 pm are awful - no better than chance

*.  Tues Jul 26, Titan 1, 5:30 pm

Gender classification, VGG with training from scratch", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.001, accuracy
layer added for training phase

We forgot to fill weights and biases :(

*.  Tues Jul 26, Titan 3, 5:21 pm

Gender classification, VGG with training from scratch", baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.0001, accuracy
layer added for training phase

We forgot to fill weights and biases :(

*.  Weds Jul 27, Titan 1 around 7:30 am

Gender classification, new 7-layer face net, baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.0003, accuracy
layer added for training phase

validation accuracy around 67% after 88K iterations

*.  Weds Jul 27, Titan 1 around 9:15 am

Gender classification, new 7-layer face net, baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.003, accuracy
layer added for training phase

validation accuracy around 80% after 113K iterations

*.  Weds Jul 27, Titan 3 around 9:22 am

Gender classification, new 7-layer face net, baseline set of
O(20K) female + O(20K) male faces, base learning rate = 0.001, accuracy
layer added for training phase

validation accuracy around 79.4% after 113K iterations
Loss curve looks good.  Training and validation accuracies indicate current
model overfits.

*.  Weds Jul 27, Titan 1 around noontime

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Two dropout ratios increased from 0.5 to 0.66.

validation accuracy asymptotes to  80%

*.  Weds Jul 27, Titan 3 around noontime

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.010, accuracy layer added for
training phase, Drop ratios retained at default 0.5

Validation accuracy asymptotes to 80%.  Converge seems somewhat faster but
not better than previous case where base learning rate = 0.003.

*.  Weds Jul 27, Titan 1 around 3:45 pm

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Two dropout node probabilities increased to 0.80.

Network takes longer to reach same asymptotic validation accuracy of around
81%

*.  Weds Jul 27, Titan 3 around noontime

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.010, accuracy layer added for
training phase, Two dropout node probabilities incrased to 0.95.  

Catastrophically bad results for accuracy.  

*.  Thurs Jul 28, Titan 1 around 6 am

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probability of node being ignore start small and increase to 0.5 towards
end of network.

After 100 epochs, we observe that inserting dropout into all layers of the
face network significantly reduces overfitting.  And asymptotic validation
accuracy is still around 81%.

*.  Thurs, Jul 28, Titan 3 around 6:07 am

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.010, accuracy layer added for
training phase; Two fully-connected layers dropout node probabilities
kept at default 0.5 values.  Weight decay regularization coeff increased
from default 0.0005 to 0.0050.

After 100 epochs, we observe that increasing weight decay definitely
reduces overfitting.  But it yields an asymptotic validation accuracy
around 78% whch is less than that for the face model with more dropout but
lower weight decay.

*.  Thurs Jul 28, Titan 1 around 7:10 am

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Xavier rather than gaussian initialization of node
weights.

Xavier weight initialization definitely does not work (at least in
custom-caffe)!  

*.  Thurs Jul 28, Titan 1 around 7:30 am

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.

Increased number of nodes in each layer by 32.
Weight decay = 0.0005
Slightly greater overfitting compared to lower-capacity network
Validation accuracy asymptotes around 81%

*.  Thurs Jul 28, Titan 3 around 7:40 am

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.

Increased number of nodes in each layer by 32.
Weight decay = 0.0010
Slightly greater overfitting compared to lower-capacity network.  But
perhaps somewhat less due than the weight decay = 0.0005 case.
Validation accuracy asymptotes around 81%

Conclusion:  If we use a higher-capacity network, we should probably
increase weight decay to partially counter overfitting.

*.  Thurs Jul 28, Titan 1 around 2 pm

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.
Weight decay = 0.0005.  4x augmented imagery set.

Validation accuracy asymptotes around 86%

*.  Thurs Jul 28, Titan 3 around 2 pm

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.  Increased number
of nodes in each layer by 32.  Weight decay = 0.0010.  4x augmented imagery
set.

Validation accuracy asymptotes around 87.8%

*.  Fri Jul 29, Titan 1 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.
Weight decay = 0.0005.  4x augmented imagery set.  2nd, 3rd... faces in
chips blackened out.  Imagery data broken apart into training, validation
and testing subsets.

Validation accuracy asymptotes around 85.3%

*.  Fri Jul 29, Titan 3 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.  Increased number
of nodes in each layer by 32.  Weight decay = 0.0010.  4x augmented imagery
set. 2nd, 3rd, ... faces in chips blackened out.  Imagery data broken apart
into training, validation and testing subsets.

Validation accuracy asymptotes around 87.1%

Conclusion: Blacking out 2nd, 3rd,... faces appears to DECREASE
gender classification performance!

*.  Sat, Jul 30, Titan 1 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.
Weight decay = 0.0005.  2nd, 3rd... faces in
chips blackened out.  Imagery data broken apart into training, validation
and testing subsets.  Image chips smaller than 48x48 doubled in sized.

Training started at 12:06 pm

Validation accuracy asymptotes around 82.3% which is better than the 81%
found on Thurs Jul 28, Titan 1 around 6 am.

*.  Sat, Jul 30, Titan 3 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.  Increased number
of nodes in each layer by 32.  Weight decay = 0.0010.  2nd, 3rd, ... faces
in chips blackened out.  Imagery data broken apart into training,
validation and testing subsets.  Image chips smaller than 48x48 doubled in
size.

Validation accuracy asymptotes around 81.6% which is slightly better than
the 81% found on Thurs Jul 28, Titan 3 around 7:40 am.

Conclusion:  Doubling image chips whose pixel sizes are less than 48x48
leads to slightly improved gender classification performance.

----------------

*.  Sat, Jul 30, Titan 1 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.  Weight decay =
0.0005.  4x augmented imagery set.  Imagery data broken apart into
training, validation and testing subsets.  Image chips smaller than 48x48
doubled in size.

Validation accuracy asymptotes around 83.0 which is noticeably worse than
the 85.3% value found on Fri Jul 29 on Titan1 !!!

train_iter_204244.caffemodel

1036 validation set:

n_correct = 857 n_incorrect = 179 frac_correct = 0.82722
Confusion matrix:

0	0	0	
0	432	71	
0	108	425	

3158 testing set:

n_correct = 2668 n_incorrect = 490 frac_correct = 0.844839
Confusion matrix:

0	0	0	
0	1416	165	
0	325	1252	

*.  Sat, Jul 30, Titan 3 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.  Increased number
of nodes in each layer by 32.  Weight decay = 0.0010.  4x augmented imagery
set.  Imagery data broken apart into training, validation and testing
subsets.  Image chips smaller than 48x48 doubled in size.

Validation accuracy asymptotes around 83.9% which is much worse than
the 87.1% value found on Fri Jul 29 on Titan3 !!!

train_iter_204145.caffemodel

1036 validation set: 

n_correct = 882 n_incorrect = 154 frac_correct = 0.851351
Confusion matrix:

0	0	0	
0	441	62	
0	92	441	

3158 testing set:

n_correct = 2704 n_incorrect = 454 frac_correct = 0.856238
Confusion matrix:

0	0	0	
0	1407	174	
0	280	1297	

----------------

*.  Sun, Jul 31, Titan 1 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces, base learning rate = 0.003,
accuracy layer added for training phase, Dropout added into all layers of
network.  Dropout probabilities of nodes being ignored start small and
increase to 0.5 toward end of network.  Gaussian initialize of all node
weights.  Weight decay = 0.0005.  4x augmented imagery set.  Imagery data
broken apart into training, validation and testing subsets.  Image chips
smaller than 48x48 doubled in size.

*.  Sun, Jul 31, Titan 3 

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces, base learning rate = 0.003,
accuracy layer added for training phase, Dropout added into all layers of
network.  Dropout probabilities of nodes being ignored start small and
increase to 0.5 toward end of network.  Gaussian initialize of all node
weights.  Increased number of nodes in each layer by 32.  Weight decay =
0.0010.  4x augmented imagery set.  Imagery data broken apart into
training, validation and testing subsets.  Image chips smaller than 48x48
doubled in size.

----------------
*.  Mon, Aug 1, Titan 3

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces, base learning rate = 0.003, accuracy layer added for
training phase, Dropout added into all layers of network.  Dropout
probabilities of nodes being ignored start small and increase to 0.5 toward
end of network.  Gaussian initialize of all node weights.  Weight decay =
0.0005.  Imagery data broken apart into training, validation and testing
subsets.  Image chips smaller than 48x48 doubled in size.  

Training, validation and testing images all have pixel size 96x96.  Set
constant mean RGB color value = 114.45.

Smoothed asymptotic training accuracy around 98.7%
Asymptotic validation accuracy around 79.6%

----------------
*.  Tues, Aug 2, Titan 1, morning

184440 combined original + Adience faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces, base learning rate = 0.003,
accuracy layer added for training phase, Dropout added into all layers of
network.  Dropout probabilities of nodes being ignored start small and
increase to 0.5 toward end of network.  Gaussian initialize of all node
weights.  Weight decay = 0.0005.  4x augmented imagery set.  Imagery data
broken apart into training, validation and testing subsets.  Image chips
smaller than 48x48 doubled in size.

Asymptotic validation accuracy around 84.8%

1036 validation set:

n_correct = 1063 n_incorrect = 180 frac_correct = 0.855189
Confusion matrix:

0	0	0	
0	507	79	
0	101	556	

3158 testing set:

n_correct = 3286 n_incorrect = 536 frac_correct = 0.859759
Confusion matrix:

0	0	0	
0	1666	205	
0	331	1620	

*.  Tues, Aug 2, Titan 3, morning

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces, base learning rate = 0.003,
accuracy layer added for training phase, Dropout added into all layers of
network.  Dropout probabilities of nodes being ignored start small and
increase to 0.5 toward end of network.  Gaussian initialize of all node
weights.  Increased number of nodes in each layer by 32.  Weight decay =
0.0010.  4x augmented imagery set.  Imagery data broken apart into
training, validation and testing subsets.  Image chips smaller than 48x48
doubled in size.

Asymptotic validation accuracy around 85.0%

1036 validation set:

n_correct = 1065 n_incorrect = 178 frac_correct = 0.856798
Confusion matrix:

0	0	0	
0	510	76	
0	102	555

3158 testing set:

n_correct = 3290 n_incorrect = 532 frac_correct = 0.860806
Confusion matrix:

0	0	0	
0	1648	223	
0	309	1642	

*.  Tues, Aug 2, Titan 1, afternoon

184440 combined original + Adience faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces, base learning rate = 0.003,
accuracy layer added for training phase, Dropout added into all layers of
network.  Dropout probabilities of nodes being ignored start small and
increase to 0.5 toward end of network.  Gaussian initialize of all node
weights.  Increased number of nodes in each layer approx 64.  Weight decay
= 0.0010.  4x augmented imagery set.  Imagery data broken apart into
training, validation and testing subsets.  Image chips smaller than 48x48
doubled in size.

Training started around 3 pm
train_iter_262918.caffemodel
Asymptotic validation accuracy around 86.5%

1036 validation set:

n_correct = 1081 n_incorrect = 162 frac_correct = 0.86967
Confusion matrix:

0	0	0	
0	522	64	
0	98	559	


3158 testing set:

n_correct = 3303 n_incorrect = 519 frac_correct = 0.864207
Confusion matrix:

0	0	0	
0	1667	204	
0	315	1636	


*.  Tues, Aug 2, Titan 3, afternoon

184440 combined original + Adience faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces, base learning rate = 0.003,
accuracy layer added for training phase, Dropout added into all layers of
network.  Dropout probabilities of nodes being ignored start small and
increase to 0.5 toward end of network.  Gaussian initialize of all node
weights.  Increased number of nodes in each layer approx 96.  Weight decay
= 0.0010.  4x augmented imagery set.  Imagery data broken apart into
training, validation and testing subsets.  Image chips smaller than 48x48
doubled in size.

Training started around 3 pm
train_iter_262741.caffemodel

Asymptotic validation accuracy around 86.1%

1036 validation set:

n_correct = 1072 n_incorrect = 171 frac_correct = 0.86243
Confusion matrix:

0	0	0	
0	521	65	
0	106	551	

3158 testing set:
n_correct = 3323 n_incorrect = 499 frac_correct = 0.86944
Confusion matrix:

0	0	0	
0	1681	190	
0	309	1642	

*.  Weds, Aug 3, Titan 1, morning

260788 combined original + Adience + Iranian faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces + 300 Iranian females, base
learning rate = 0.003, accuracy layer added for training phase, Dropout
added into all layers of network.  Dropout probabilities of nodes being
ignored start small and increase to 0.5 toward end of network.  Gaussian
initialize of all node weights.  Increased number of nodes in each layer
approx 64.  Weight decay = 0.0010.  6x augmentation of our 40K faces, 2X
augmentation of Adience and Iranian female faces.  Imagery data broken
apart into training, validation and testing subsets.  Image chips smaller
than 48x48 doubled in size.

Training started around 6:50 am
train_iter_160000.caffemodel
Asymptotic validation accuracy around 86.6%


1139 validation set:

n_correct = 947  n_male_correct = 484   n_female_correct = 463
n_incorrect = 132  n_male_incorrect = 43   n_female_incorrect = 89
n_unsure = 69
frac_correct = 0.831431  frac_unsure = 0.0526778  frac_incorrect = 0.115891
frac_male_correct = 0.921147  frac_female_correct = 0.824561

Confusion matrix:

0	0	0	0
0	484     43      44
0	89      463     16 
0       0       0       0

male_score_threshold = 0.625  female_score_threshld = 0.525
incorrect_weight_frac = 0.7

3507 testing set:
n_correct = 2905  n_male_correct = 1542   n_female_correct = 1363
n_incorrect = 422  n_male_incorrect = 132   n_female_incorrect = 290
n_unsure = 180
frac_correct = 0.828343  frac_unsure = 0.0513259  frac_incorrect = 0.120331
frac_male_correct = 0.921147  frac_female_correct = 0.824561

Confusion matrix:

0	0	0	0
0	1542    132     145
0	290     1363    35 
0       0       0       0

male_score_threshold = 0.625  female_score_threshld = 0.525
incorrect_weight_frac = 0.7

For comparison, results from previous best train_iter_262741.caffemodel for
this newer, larger and apparently more stressing test set:

n_correct + n_incorrect = 3507
n_correct = 2969 n_incorrect = 538 frac_correct = 0.846593
Confusion matrix:

0	0	0	
0	1610	209	
0	329	1359	

*.  Weds, Aug 3, Titan 3, morning

260788 combined original + Adience + Iranian faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces + 300 Iranian females, base
learning rate = 0.001, accuracy layer added for training phase, Dropout
added into all layers of network.  Dropout probabilities of nodes being
ignored start small and increase to 0.5 toward end of network.  Gaussian
initialize of all node weights.  Increased number of nodes in each layer
approx 64.  Weight decay = 0.0010.  6x augmentation of our 40K faces, 2X
augmentation of Adience and Iranian female faces.  Imagery data broken
apart into training, validation and testing subsets.  Image chips smaller
than 48x48 doubled in size.

Training started around 6:50 am
train_iter_200000.caffemodel
Asymptotic validation accuracy around 84.4

1139 validation set:

n_correct + n_incorrect = 1139
n_correct = 968 n_incorrect = 171 frac_correct = 0.849868
Confusion matrix:

0	0	0	
0	491	80	
0	91	477	


3507 testing set:
n_correct + n_incorrect = 3507
n_correct = 2969 n_incorrect = 538 frac_correct = 0.846593
Confusion matrix:

0	0	0	
0	1600	219	
0	319	1369	

-----------
*.  Sat, Aug 6, Titan 1, morning

350K combined original + Adience + Iranian faces + non-faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces + 300 Iranian females + O(90K)
non-faces , base learning rate = 0.003, accuracy layer added for training
phase, Dropout added into all layers of network.  Dropout probabilities of
nodes being ignored start small and increase to 0.5 toward end of network.
Gaussian initialize of all node weights.  Increased number of nodes in each
layer approx 64.  Weight decay = 0.0010.  6x augmentation of our 40K faces,
2X augmentation of Adience and Iranian female faces.  Imagery data broken
apart into training, validation and testing subsets.  Image chips smaller
than 48x48 doubled in size.

Training started around 7 am

Validation set results:

n_correct = 1352 n_male_correct = 470 n_female_correct = 415
n_incorrect = 179 n_male_incorrect = 79 n_female_incorrect = 86
 n_unsure = 89
frac_correct = 0.834568 frac_unsure = 0.0549383 frac_incorrect = 0.110494
frac_nonface_correct = 0.970894 frac_male_correct = 0.856102 frac_female_correct = 0.828343
Confusion matrix:

467	14	1	0	
19	470	60	22	
11	75	415	67	
0	0	0	0	

male_score_threshold = 0.52 female_score_threshold = 0.58

Testing set results:

n_correct = 3777 n_male_correct = 1518 n_female_correct = 1254
n_incorrect = 499 n_male_incorrect = 222 n_female_incorrect = 260
 n_unsure = 253
frac_correct = 0.833959 frac_unsure = 0.0558622 frac_incorrect = 0.110179
frac_nonface_correct = 0.983366 frac_male_correct = 0.872414 frac_female_correct = 0.828269
Confusion matrix:

1006	22	1	0	
45	1518	177	79	
23	237	1254	174	
0	0	0	0	


male_score_threshold = 0.52 female_score_threshold = 0.58



*.  Sat, Aug 6, Titan 3, morning

350K combined original + Adience + Iranian faces + non-faces used for training.

Gender classification, new 7-layer face net, baseline set of O(20K) female
+ O(20K) male faces + 17K Adience faces + 300 Iranian females + O(90K)
non-faces , base learning rate = 0.01, accuracy layer added for training
phase, Dropout added into all layers of network.  Dropout probabilities of
nodes being ignored start small and increase to 0.5 toward end of network.
Gaussian initialize of all node weights.  Increased number of nodes in each
layer approx 64.  Weight decay = 0.0010.  6x augmentation of our 40K faces,
2X augmentation of Adience and Iranian female faces.  Imagery data broken
apart into training, validation and testing subsets.  Image chips smaller
than 48x48 doubled in size.

Training started around 7 am

Validation set results:

input_images_subdir = /data/caffe/faces/image_chips/validation/Aug2_imfdb_Iran_nonface_96x96/
n_correct = 1360 n_male_correct = 475 n_female_correct = 416
n_incorrect = 160 n_male_incorrect = 72 n_female_incorrect = 78
 n_unsure = 98
frac_correct = 0.840544 frac_unsure = 0.0605686 frac_incorrect = 0.0988875
frac_nonface_correct = 0.979123 frac_male_correct = 0.868373 frac_female_correct = 0.842105
Confusion matrix:

469	3	10	0	
17	475	55	24	
14	64	416	74	
0	0	0	0	

male_score_threshold = 0.52 female_score_threshold = 0.58

Testing set results:

input_images_subdir = /data/caffe/faces/image_chips/testing/Aug2_imfdb_Iran_nonface_96x96/

n_correct = 3801 n_male_correct = 1553 n_female_correct = 1239
n_incorrect = 468 n_male_incorrect = 210 n_female_incorrect = 241
 n_unsure = 264
frac_correct = 0.838518 frac_unsure = 0.0582396 frac_incorrect = 0.103243
frac_nonface_correct = 0.983431 frac_male_correct = 0.880885 frac_female_correct = 0.837162
Confusion matrix:

1029 non-face test chips
1819 male face test chips
1688 female face test chips

1012	3	14	0	
51	1553	159	56	
25	216	1239	208	
0	0	0	0	

1.67% of non-face chips are incorrectly classified
11.54% of male-face chips are incorrectly classified
14.28% of female-face chips are incorrectly classified
Weighted average percentage of incorrectly classified chips = 0.1032

male_score_threshold = 0.52 female_score_threshold = 0.58

***************************************************************
As of 8/8/16, this is our BEST gender classification result.
**************************************************************

TODO:

*.  Break out all Magick++ methods in videofuncs and imagefuncs namespaces
into new magickfuncs namespace sitting in src/images/

*.  Write C++ code to look at first few weights in each layer after a model
has been trained.  Also compute mean weight value for each layer.

