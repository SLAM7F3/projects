// ====================================================================
// Program HOG_OBJECT_DETECTOR is a minor variant of Davis King's HOG
// template-based object detector.  When run in "training" mode, it
// imports an XML file generated by Davis' IMGLAB program that
// contains bounding boxes around objects (e.g. human faces) for some
// number of trained images.  This program exports a fitted HOG
// template.  When run in "testing" mode, it imports the fitted HOG
// template and searches for matching objects in some corpus of
// unlabeled images.  
// ====================================================================
// Last updated on 11/29/13; 11/30/13; 12/1/13
// ====================================================================

#include <fstream>
#include <iostream>
#include <string>
#include <vector>

#include <dlib/svm_threaded.h>
#include <dlib/gui_widgets.h>
#include <dlib/array.h>
#include <dlib/array2d.h>
#include <dlib/image_keypoint.h>
#include <dlib/image_processing.h>
#include <dlib/cmd_line_parser.h>
#include <dlib/data_io.h>

#include "general/filefuncs.h"
#include "math/mathfuncs.h"
#include "general/outputfuncs.h"
#include "general/stringfuncs.h"
#include "time/timefuncs.h"

using std::cin;
using std::cout;
using std::endl;
using std::exception;
using std::flush;
using std::ifstream;
using std::ios;
using std::ofstream;
using std::string;
using std::vector;

int main(int argc, char** argv)
{  

//   const int pyramid_levels=6;
//   const int pyramid_levels=8;
   const int pyramid_levels=10;

   try
   {
      timefunc::initialize_timeofday_clock(); 

      dlib::command_line_parser parser;
      parser.add_option("train", "Train HOG template from labeled bboxes");
      parser.add_option("test", "Test HOG template on unlabeled images");
      parser.add_option("bootstrap", "testing feedback input to training");
      parser.add_option("h", "show help");

      parser.parse(argc, argv);

      if (parser.option("h"))
      {
         parser.print_options();
         return 0;
      }

      if (parser.option("train"))
      {
         dlib::array<dlib::array2d<unsigned char> > images;
         std::vector<std::vector<dlib::rectangle> > object_locations;
         std::vector<std::vector<dlib::rectangle> > removed_locations;

         if (parser.number_of_arguments() != 1)
         {
            cout << "Specify XML file with training data!" << endl;
            return 1;
         }

// 3rd argument below is label entered with bboxes
// 4th argument below is true only when we want to ignore all images
// with NO bboxes

         string bbox_label="";
//         bool ignore_images_w_no_bboxes_flag=true;
         bool ignore_images_w_no_bboxes_flag=false;

         std::vector<std::vector<dlib::rectangle> > ignored_bboxes=
            dlib::load_image_dataset(
               images, object_locations, parser[0], bbox_label.c_str(),
               ignore_images_w_no_bboxes_flag);

         cout << "images.size(): " << images.size() << endl;
         cout << "object_locations.size() = " << object_locations.size()
              << endl;

// Compute median bbox aspect ratio:

         vector<double> aspect_ratios;
         for (unsigned int i=0; i<object_locations.size(); i++)
         {
            for (unsigned int r=0; r<object_locations[i].size(); r++)
            {
               int width=object_locations[i].at(r).width();
               int height=object_locations[i].at(r).height();
               aspect_ratios.push_back(double(width)/double(height));
            } // loop over index r labeling bboxes for ith training image
         } // loop over index i labeling training images
         double median_bbox_aspect_ratio=mathfunc::median_value(aspect_ratios);
         cout << "Median bbox aspect ratio = "
              << median_bbox_aspect_ratio << endl;

// Next command flips images plus their manually selected bboxes.
// Training set is doubled by this procedure:

         bool enforce_left_right_symmetry_flag=true;
//         bool enforce_left_right_symmetry_flag=false;
         if (enforce_left_right_symmetry_flag)
         {
            dlib::add_image_left_right_flips(
               images,object_locations,ignored_bboxes);
         }

         typedef dlib::scan_fhog_pyramid<dlib::pyramid_down<pyramid_levels> > 
            image_scanner_type;
         image_scanner_type scanner;

// Filter size measured in pixels (probably width x height):

//         scanner.set_detection_window_size(80,80);
//         scanner.set_detection_window_size(80,100);	// frontal face
//         scanner.set_detection_window_size(90,100);	// upper torso
//         scanner.set_detection_window_size(65,85);	// right face profile

//         int detection_window_width=50;		// right face profile
//         int detection_window_width=65;		// right face profile
         int detection_window_width=40;	// standing person
         int detection_window_height=detection_window_width/
            median_bbox_aspect_ratio;
         cout << "Detection window width = " 
              << detection_window_width
              << " detection_window_height = "
              << detection_window_height << endl;
         scanner.set_detection_window_size(
            detection_window_width,detection_window_height);	

// Davis insists that the following line [which encourages filters to
// be separable (i.e. they can be expressed as small sums of vector 
// outerproducts) ] is generally good:

//         scanner.set_nuclear_norm_regularization_strength(1);
         scanner.set_nuclear_norm_regularization_strength(2);

         dlib::structural_object_detection_trainer<image_scanner_type> 
            trainer(scanner);
         trainer.set_num_threads(6); 

// C=80 seems reasonable for right/left face profile HOG template training
// C=300 yields 80% recall on training bboxes for standing people

//         double c_value=20;	// no nuclear norm term present in score func
//         double c_value=80;
//         double c_value=100;
         double c_value=300;
         trainer.set_c(c_value); // increase c when nuclear norm term is
  		                 // present in objective function
         trainer.set_epsilon(0.10);
         trainer.be_verbose();

// Automatically purge bboxes which are too inconsistent with returned
// results.  This next call should be made with care (to avoid
// training on bad bboxes)....

         removed_locations=dlib::remove_unobtainable_rectangles(
            trainer,images,object_locations);


         dlib::object_detector<image_scanner_type> detector = 
            trainer.train(images,object_locations,ignored_bboxes);

/*
// Recall from disk.

         ifstream fin("object_detector.dat", ios::binary);
         object_detector<image_scanner_type> detector;
         deserialize(detector, fin);
*/

         dlib::image_window hogwin(dlib::draw_fhog(detector));
         cout << "num filter: "<< dlib::num_separable_filters(detector) 
              << endl;

// We can easily test the new detector against our training data.
// This print statement will indicate that it has perfect precision
// and recall on this simple task.  It will also print the average
// precision (AP).

         cout << "Test detector (precision,recall,AP): " 
              << test_object_detection_function(
                 detector,images,object_locations) << endl;

// The cross validation should also indicate perfect precision and
// recall.
         //cout << "3-fold cross validation (precision,recall,AP): " << cross_validate_object_detection_trainer(trainer, images, object_locations, 3) << endl;


// Finally, note that the detector can be serialized to disk just like
// other dlib objects.

         ofstream fout("object_detector.dat", ios::binary);
         dlib::serialize(detector, fout);
         fout.close();

// Let's display the output of the detector along with our training
// images.

         dlib::image_window win;
         int iskip=1;
         for (unsigned int i = 0; i < images.size(); i += iskip)
         {
            // Run the detector on images[i] 
            const std::vector<dlib::rectangle> rects = detector(images[i]);
            cout << "Number of detections: "<< rects.size() << endl;

            // Put the image and detections into the window.
            win.clear_overlay();
            win.set_image(images[i]);
            win.add_overlay(rects, dlib::rgb_pixel(255,0,0));
            win.add_overlay(object_locations[i],dlib::rgb_pixel(0,255,0));
            win.add_overlay(removed_locations[i],dlib::rgb_pixel(0,0,255));
            win.add_overlay(ignored_bboxes[i],dlib::rgb_pixel(255,0,255));

            if (rects.size() > 0)
            {
               cout << "Hit enter to see the next image.";
               cin.get();
            }
         }

         cout << "Finished training HOG template" << endl;
         outputfunc::print_elapsed_time();

         return 0;
      }

      if (parser.option("test"))
      {

// Import trained HOG template file from disk:

         if (parser.number_of_arguments() != 2)
         {
            cout << "Must pass trained HOG template filename!" << endl;
            return 1;
         }
         string HOG_template_filename(parser[1]);
         cout << "Imported HOG template filename = "
              << HOG_template_filename << endl;
         ifstream fin(HOG_template_filename.c_str(), ios::binary);

         typedef dlib::scan_fhog_pyramid<dlib::pyramid_down<pyramid_levels> > 
            image_scanner_type;
         dlib::object_detector<image_scanner_type> detector;
         dlib::deserialize(detector, fin);

         dlib::array<dlib::array2d<unsigned char> > images;
         std::vector<std::vector<dlib::rectangle> > object_locations;

         if (parser.number_of_arguments() != 2)
         {
            cout << "Must pass XML file with testing data!" << endl;
            return 1;
         }
         std::vector<std::vector<dlib::rectangle> > ignored_bboxes=
            dlib::load_image_dataset(images,object_locations,parser[0]);

         cout << "images.size(): " << images.size() << endl;
         //cout << "Test detector (precision,recall,AP): " << test_object_detection_function(detector, images, object_locations) << endl;

         int n_templates=detector.num_detectors();
         cout << "Number of HOG templates in input detector = "
              << n_templates << endl;

         cout << "Number of separable filters="
              << dlib::num_separable_filters(detector) << endl;

         //cout << "Test detector (precision,recall,AP): " << test_object_detection_function(detector, images, object_locations) << endl;

// Display output of the detector along with our training images:

         string bbox_filename="object_bboxes.dat";
         ofstream bbox_stream;

//         bool display_bboxes_flag=true;
         bool display_bboxes_flag=false;
         if (!display_bboxes_flag)
         {
            string banner="Exporting object bboxes to "+bbox_filename;
            outputfunc::write_banner(banner);
         
            filefunc::openfile(bbox_filename,bbox_stream);
            bbox_stream << "# image_index bbox_index Ulo Uhi Vlo Vhi" 
                        << endl << endl;
         }
         else
         {
            for (int d=0; d<n_templates; d++)
            {
               dlib::image_window hogwin(dlib::draw_fhog(detector,d));
               outputfunc::enter_continue_char();
            }
         }
         
         dlib::image_window win;
         int iskip=1;
         for (unsigned int i = 0; i < images.size(); i += iskip)
         {
            double progress_frac=double(i)/images.size();
            outputfunc::print_elapsed_and_remaining_time(progress_frac);

            // Run the detector on images[i] 
            const std::vector<dlib::rectangle> rects = detector(images[i]);
            cout << "Image index = " << i 
                 << " Number of detections: "<< rects.size() << endl;

            if (!display_bboxes_flag)
            {

// Export object bboxes to output text file:

               int width=images[i].nc();
               int height=images[i].nr();
               for (unsigned int r=0; r<rects.size(); r++)
               {
                  dlib::rectangle curr_rect(rects[r]);
                  double Ulo=double(curr_rect.left())/height;
                  double Uhi=double(curr_rect.right())/height;
                  double Vlo=1-double(curr_rect.bottom())/height;
                  double Vhi=1-double(curr_rect.top())/height;

                  bbox_stream << i << "  " << r << "  "
                              << Ulo << "  " << Uhi << "  "
                              << Vlo << "  " << Vhi << endl;
               } // loop over index r labeling bboxes
            }
            else
            {

// Draw the image and object detection bboxes within the window:

               win.clear_overlay();
               win.set_image(images[i]);
               win.add_overlay(
                  rects, dlib::rgb_pixel(255,0,0));
               win.add_overlay(
                  object_locations[i],dlib::rgb_pixel(0,255,0));
               win.add_overlay(
                  ignored_bboxes[i],dlib::rgb_pixel(255,0,255));

               if (rects.size() > 0)
               {
                  unsigned long key;
                  bool is_printable;
                  win.get_next_keypress(key,is_printable);
//                  cout << "key = " << key 
//                       << " is_printable = " << is_printable << endl;
                  if (key==dlib::base_window::KEY_LEFT)
                  {
                     iskip=-1;
                  }
                  else if (key==dlib::base_window::KEY_RIGHT)
                  {
                     iskip=1;
                  }
               } // rects.size() > 0 conditional
            } // display_bboxes_flag conditional
         } // loop over index i labeling images

         if (!display_bboxes_flag)
         {
            filefunc::closefile(bbox_filename,bbox_stream);
         }

         return 0;
      } // test parser option conditional

      if (parser.option("bootstrap"))
      {

         // Recall trained HOG template from disk.
         ifstream fin("object_detector.dat", ios::binary);
         typedef dlib::scan_fhog_pyramid<dlib::pyramid_down<pyramid_levels> > 
            image_scanner_type;
         dlib::object_detector<image_scanner_type> detector;
         dlib::deserialize(detector, fin);

         dlib::image_dataset_metadata::dataset curr_dataset;
         dlib::image_dataset_metadata::load_image_dataset_metadata(
            curr_dataset,parser[0]);
            
            
         dlib::array<dlib::array2d<unsigned char> > images;
         std::vector<std::vector<dlib::rectangle> > object_locations;
         std::vector<std::vector<dlib::rectangle> > ignored_bboxes;

         if (parser.number_of_arguments() != 1)
         {
            cout << "Specify XML file with testing data!" << endl;
            return 1;
         }
         ignored_bboxes=dlib::load_image_dataset(
            images,object_locations,parser[0]);

         cout << "images.size(): " << images.size() << endl;
         //cout << "Test detector (precision,recall,AP): " << test_object_detection_function(detector, images, object_locations) << endl;


         cout << "Number of separable filters = "
              << dlib::num_separable_filters(detector) << endl;

         for (unsigned int i = 0; i < images.size(); i++)
         {
            // Run the detector on images[i] 
            const std::vector<dlib::rectangle> rects = detector(images[i]);
            curr_dataset.images[i].boxes.clear();
            curr_dataset.images[i].boxes.resize(rects.size());

            for (unsigned int r=0; r<rects.size(); r++)
            {
               curr_dataset.images[i].boxes[r].rect=rects[r];
               string curr_label="";
               curr_dataset.images[i].boxes[r].label=curr_label;
            }
         }

         dlib::image_dataset_metadata::save_image_dataset_metadata(
            curr_dataset,"bootstrap.xml");
         return 0;
      }
   }

   catch (exception& e)
   {
      cout << "\nexception thrown!" << endl;
      cout << e.what() << endl;
   }
}

