========================================================================
Text recognition README
========================================================================
Last updated on 7/12/12; 7/27/12; 8/7/12; 11/24/12
========================================================================

---------------------------------------
SYNTHETIC CHARACTER GENERATION PROGRAMS
---------------------------------------

*.  Program mains/imagetext/CHARS2PNGS is a variant of WORDS2JPGS.  It
first generates png images of synthetic characters using the PNGWRITER
program.  The UV image is initially oriented in the YZ world-plane.  It is
rotated through az about the world z axis, el about the world y-axis and
roll about the the world x-axis.  The az, el and roll angles are random
variables selected from gaussian distributions with reasonable standard
deviations to simulate camera views of text in the wild.

The rotated synthetic character image is subsequently projected back into
the YZ world-plane.  The projected image is cropped so that the rotated
character fills most of the projection.  Finally, the cropped character is
scaled so that its height equals 32 pixels in size.

*.  Program mains/imagetext/CHARS2REGIONS imports synthesized text
character images generated by CHARS2PNGS.  In July 2012, we empirically
found that synthetic text characters generally have a nontrivial intensity
distribution.  So for each character image, we could a reasonable threshold
that can be used to convert it into a binary image.  After binarizing,
CHARS2REGIONS next counts the number of connected components.  It moves all
binary text character images containing a single connected component into
single_component_subdir.

*.  Program mains/imagetext/GENERATE_CHAR_IMAGES is a generalization of
CHARS2PNGS.  It first generates png images of synthetic characters using
the PNGWRITER program.

The UV image is initially oriented in the YZ world-plane.  It is rotated
through az about the world z axis, el about the world y-axis and roll about
the the world x-axis.  The az, el and roll angles are random variables
selected from gaussian distributions with reasonable standard deviations to
simulate camera views of text in the wild.  The rotated synthetic character
image is subsequently projected back into the YZ world-plane.

Text characters are assigned random foreground and background colors.
Reasonable differences in hue, saturation and value are imposed between
foreground and background colorings.  Random linear shading is performed on
both foreground and background colors to simulate illumination variations.
Random gaussian noise is also added to the RGB color channels of every
pixel.

The projected image is cropped so that the rotated character fills most of
the projection. The cropped character is subsequently scaled so that its
height equals 32 pixels in size.  Finally, the output character image is
blurred by a gaussian with variable sigma value.

We wrote this program in July 2012 in order to easily obtain large numbers
of training examples for the Coates-Ng text classifier.

-----------------------------------------------------
COATES-NG UNSUPERVISED DICTIONARY GENERATION PROGRAMS
-----------------------------------------------------

1. Program NORMALIZE_CHARS reads in a set of image files which contain
single text characters from a directory tree.  It reassigns uniform names
to the input files of the form "12345.jpg".  NORMALIZE_CHARS also resizes
each output jpeg file so that its new height precisely equals 32 pixels.

2. Program DESCRIPTORS loops over all character image files and
extracts n_patches_per_image 8x8 pixel patches from each image.  It
converts the 8x8 patches into a 64x1 column vector of grey-scale
intensities.  Raw descriptors for all character image patches are exported
to a single HDF5 binary file.  Descriptor mean and covariance are also
recursively calculated and written to output text files.

3. Program WHITEN_DESCRIPTORS imports raw 64x1 descriptors for 8x8 pixel
patches selected from character images generated by program DESCRIPTORS.
It also imports the descriptors' mean and inverse square root covariance
matrix which were previously output by DESCRIPTORS.  The mean is subtracted
from each raw descriptor, and the residual is multiplied by the inverse
square root covariance matrix in order to "whiten" it.  Whitened patch
descriptors are exported to a single HDF5 binary file.

4.  Program DICTIONARY imports whitened 64x1 descriptors generated by
program WHITEN_DESCRIPTORS for 8x8 pixel patches X^i randomly selected from
text character jpeg images.  It initially assigns each patch to some random
cluster labeled by 0 <= k < K. Score vectors S^i associated with each pixel
patch are then computed which have precisely one non-zero entry.  We then
iteratively solve for the 64xK dictionary matrix D which minimizes sum_i |D
S^i - X^i|.  Columns within D are subsequently renormalized to have unit
magnitude.  The final values in D are exported to a binary HDF5 file.

After each iteration, a PNG file is generated which shows all K 8x8
descriptors within the dictionary.

5. Program NORMALIZE_WORDS reads in a set of JPG files from words_subdir
which contain multi-character words from a directory tree.  It reassigns
uniform names to the input files of the form "12345.jpg".  NORMALIZE_WORDS
also resizes each input jpg file so that its new height precisely equals 32
pixels.

6. Program CHOP_WORDS reads in a set of JPG files output by NORMALIZE_WORDS
containing multi-character words.  The vertical height of each image file
should precisely equal 32 pixels in size.  It excises 32x32 "window" images
and shifts 16 pixels over for each new window.  The exported images have
filenames of the form text_123456.jpg.

7. Program EXTRACT_NONTEXT searches for JPG, PNG and GIF files within
training_data/not_text/ .  Randomly looping over all such non-text image
files, it randomly chooses a 32x32 window within some image.  If the image
entropy for the random window exceeds a minimal threshold, EXTRACT_NONTEXT
exports it to a file with name of the form nontext_123456.jpg.

8.  Program POOL_FEATURES reads in a set of text or non-text images files
from a specified input subdirectory.  The width or height for each input
image should precisely equal 32 pixels in size, but both need not equal 32.
It also imports a precomputed character dictionary along with whitening
mean and covariance matrices.  Looping over each input window file,
POOL_FEATURES extracts 8x8 patches in each window with pixel for every
possible ~25x~25 pixel offset.  Each 8x8 patch is projected onto the
dictionary and converted into a K-dimensional histogram. The histogram
descriptors are averaged together within 3x3 regions of the ~32x~32 window.
So the final descriptor for each ~32x~32 window is a 9*K dimensional
vector.  The 9*K dimensional window descriptors for all valid ~32x~32
windows are exported to windows_descriptors.hdf5.

9. Program SVM_TEXT reads in 9xK dimensional features for N ~32x~32 text
windows and N 32x32 non-text windows generated by POOL_FEATURES.  It then
uses Davis King's DLIB library to load the input samples along with their
positive and negative labels.  After the ordering of the input samples is
randomized, cross-correlation is performed in order to estimate a
reasonable value for a linear-SVM slack variable C.  DLIB then trains
binary decision and probabilistic decision functions.  A serialized version
of the probabilistic decision function is exported to an output binary
file.

------------------------
EXTREMAL REGION PROGRAMS
------------------------

*. Program GENERATE_EXTREMAL_REGIONS is a specialized variant of
SHAPE_DESCRIPTORS.  It is designed to output extremal regions for text and
non-text images which are only 32 pixels high.  GENERATE_EXTREMAL_REGIONS
works with images containing bright characters against dark backgrounds or
vice versa (or else non-text input imagery).  It varies a binary threshold
from 0 to 255 and generates connected binary component images.  If the
number of connected components or fill fraction is too large or small, this
program ignores the candidate image.  Otherwise, it retains some a small
fraction of extremal region image examples corresponding to random
threshold settings.

*. Program COMPUTE_SHAPE_DESCRIPTORS imports connected components
corresponding to previously thresholded text and non-text character regions
generated by programs GENERATE_EXTREMAL_REGIONS and
NONTEXT_EXTREMAL_REGIONS.  Following Neumann and Matas, "Real-time scene
text localization and recognition", CVPR 2012, we compute 4-dimensional
feature descriptors for each extremal region.  The 4D descriptors are
written to output text files.

*. Program SVM_SHAPE reads in shape descriptors for text and non-text which
were previously generated by COMPUTE_SHAPE_DESCRIPTORS.  It uses Davis
King's DLIB library to train an SVM classifier with a gaussian a
radial-basis kernel.  Binary and probabilistic decision functions which
indicate whether a candidate extremal region may contain a text character
or not are exported in serialized DLIB formats.  Subsequent programs can
then use DLIB to import these trained decision functions.

*. Program LOCATE_CHARS imports the binary and probabilistic classifier
functions computed with a gaussian kernel exported by program SVM_SHAPE.
It first computes connected components within binary thresholded versions
of an input image for thresholds ranging from 255 down to 0.  Following
Neumann and Matas, "Real-time scene text localization and recognition",
CVPR 2012, we compute aspect_ratio, compactness, n_holes and median
horizontal crossings for each candidate extremal region.  These features
are mapped into a probability that the candidate corresponds to a text
character.

Entropies for surviving extremal regions are subsequently calculated.  If
the entropy does not lie within a specified interval, the candidate region
is discarded.

Finally, bounding boxes are placed around surviving candidate text
character extremal regions.  A composite displaying the locations of all
candidate text bounding boxes is exported as a jpeg image.

