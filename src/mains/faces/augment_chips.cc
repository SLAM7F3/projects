// ========================================================================
// Program AUGMENT_CHIPS imports the text file containing attributed
// face bounding box information generated by program
// ATTRIBUTE_IMAGES.  Any face whose gender is unknown is effectively
// ignored.  Among the known-gender face chips, a small percentage are
// marked for testing while a smaller percentage are designated as
// validation.  Data augmentation (translation, hsv color
// modification, noise injection) is performed on the remaining
// training images.  Female and male subdirectories are formed within
// an output tree of training, validation and testing folders.  All
// face chips are exported to one of these subdirectories after their
// pixel sizes are constrained to not exceed 96 x 96.

//			./augment_chips

// ========================================================================
// Last updated on 7/23/16; 7/29/16; 7/30/16; 7/31/16
// ========================================================================

#include <fstream>
#include <iostream>
#include <map>
#include <set>
#include <string>
#include <vector>

#include "geometry/bounding_box.h"
#include "general/filefuncs.h"
#include "image/imagefuncs.h"
#include "numrec/nrfuncs.h"
#include "general/stringfuncs.h"
#include "general/sysfuncs.h"
#include "video/texture_rectangle.h"
#include "time/timefuncs.h"
#include "video/videofuncs.h"

// ========================================================================
int main( int argc, char** argv )
{
   using std::cin;
   using std::cout;
   using std::endl;
   using std::map;
   using std::ofstream;
   using std::pair;
   using std::string;
   using std::vector;

   timefunc::initialize_timeofday_clock(); 
   std::set_new_handler(sysfunc::out_of_memory);

   int max_xdim = 96;
   int max_ydim = 96;
//   int max_xdim = 224;
//   int max_ydim = 224;

   bool rgb2grey_flag = true;		       // default as of Jun 14
   double rgb2grey_threshold = 0.2;            // default as of Jun 14
   double noise_threshold = 0.5;               // default as of Jun 14

   string faces_rootdir = "/data/TrainingImagery/faces/";
   string labeled_faces_subdir = faces_rootdir + "images/";
//   string bbox_labels_filename = labeled_faces_subdir+"labeled_face_bboxes.txt";
   string bbox_labels_filename = labeled_faces_subdir+
      "labeled_face_bboxes_sans_corrupted_imgs.txt";
   filefunc::ReadInfile(bbox_labels_filename);

   typedef map<string, vector<bounding_box> > ANNOTATED_BBOXES_MAP;
// independent string: image_ID_str
// dependent STL vector: annotated bboxes

   ANNOTATED_BBOXES_MAP annotated_bboxes_map;
   ANNOTATED_BBOXES_MAP::iterator annotated_bboxes_iter;

   bool first_image_flag = true;
   string image_ID_str = "";
   vector<bounding_box> annotated_bboxes;
   int n_total_bboxes = 0;
   int n_female_bboxes = 0;
   int n_male_bboxes = 0;
   int n_unknown_bboxes = 0;
   int n_training_bboxes = 0;
   int n_validation_bboxes = 0;
   int n_testing_bboxes = 0;

   for(unsigned int i = 0; i < filefunc::text_line.size(); i++)
   {
      string curr_line=filefunc::text_line[i];

      vector<string> substrings = stringfunc::decompose_string_into_substrings(
         curr_line);
      if(substrings[0] == "Image:")
      {
         if(first_image_flag)
         {
            first_image_flag = false;
         }
         else
         {
            // Save previous image info into data structures
            annotated_bboxes_map[image_ID_str] = annotated_bboxes;
            annotated_bboxes.clear();
         }
         annotated_bboxes.clear();
         image_ID_str = substrings[6];
      }
      else
      {
         vector<string> substrings = 
            stringfunc::decompose_string_into_substrings(curr_line);
         string bbox_label = substrings[1];
         int px_min = stringfunc::string_to_number(substrings[2]);
         int px_max = stringfunc::string_to_number(substrings[3]);
         int py_min = stringfunc::string_to_number(substrings[4]);
         int py_max = stringfunc::string_to_number(substrings[5]);
         bounding_box curr_bbox(px_min, px_max, py_min, py_max);

         colorfunc::Color bbox_color = colorfunc::black;
         if(bbox_label == "face")
         {
            bbox_color = colorfunc::red;
         }
         else if(bbox_label == "hand")
         {
            bbox_color = colorfunc::cyan;
         }

         curr_bbox.set_label(bbox_label);
         curr_bbox.set_color(bbox_color);

// Search for any bbox attribute key-value pairs:

         int n_attribute_pairs = (substrings.size() - 6)/2;
         for(int ap = 0; ap < n_attribute_pairs; ap++)
         {
            string attr_key = substrings[6 + ap * 2];
            string attr_value = substrings[6 + ap * 2 + 1];
            curr_bbox.set_attribute_value(attr_key, attr_value);
         }

         curr_bbox.set_ID(annotated_bboxes.size());

         string gender = curr_bbox.get_attribute_value("gender");
         if(gender=="female")
         {
            n_female_bboxes++;
         }
         else if(gender=="male")
         {
            n_male_bboxes++;
         }
         else if(gender=="unknown")
         {
            n_unknown_bboxes++;
         }

// Reserve 2.5% of all known bboxes for validation and 7.5% for
// testing.  The remaining 90% of known bboxes are marked for
// training:

         string attr_key = "classification_type";
         string attr_value = "training";
         double tvt = nrfunc::ran1();
         if(tvt < 0.025)
         {
            attr_value = "validation";
            n_validation_bboxes++;
         }
         else if (tvt >= 0.025 && tvt < 0.10)
         {
            attr_value = "testing";
            n_testing_bboxes++;
         }
         else
         {
            n_training_bboxes++;
         }
         curr_bbox.set_attribute_value(attr_key, attr_value);

         n_total_bboxes++;
         annotated_bboxes.push_back(curr_bbox);

      } // substrings[0] == "Image:" conditional
   } // loop over index i labeling lines in detections text file

   // Save final image info into data structures
   annotated_bboxes_map[image_ID_str] = annotated_bboxes;

   int n_known_bboxes = n_total_bboxes - n_unknown_bboxes;

   int face_ID_start = 0;
   int face_ID = face_ID_start;

   string output_chips_subdir = "./augmented_face_chips/";
   filefunc::dircreate(output_chips_subdir);
   string unknown_chips_subdir = output_chips_subdir+"unknown/";
   filefunc::dircreate(unknown_chips_subdir);

   string training_chips_subdir = output_chips_subdir+"training/";
   filefunc::dircreate(training_chips_subdir);
   string validation_chips_subdir = output_chips_subdir+"validation/";
   filefunc::dircreate(validation_chips_subdir);
   string testing_chips_subdir = output_chips_subdir+"testing/";
   filefunc::dircreate(testing_chips_subdir);

   string female_training_chips_subdir = training_chips_subdir+"female/";
   filefunc::dircreate(female_training_chips_subdir);
   string male_training_chips_subdir = training_chips_subdir+"male/";
   filefunc::dircreate(male_training_chips_subdir);

   string female_validation_chips_subdir = validation_chips_subdir+"female/";
   filefunc::dircreate(female_validation_chips_subdir);
   string male_validation_chips_subdir = validation_chips_subdir+"male/";
   filefunc::dircreate(male_validation_chips_subdir);

   string female_testing_chips_subdir = testing_chips_subdir+"female/";
   filefunc::dircreate(female_testing_chips_subdir);
   string male_testing_chips_subdir = testing_chips_subdir+"male/";
   filefunc::dircreate(male_testing_chips_subdir);

   int image_counter = 0;
   int n_images = annotated_bboxes_map.size();
   for(annotated_bboxes_iter = annotated_bboxes_map.begin();
       annotated_bboxes_iter != annotated_bboxes_map.end();
       annotated_bboxes_iter++)
   {
      if(image_counter%100 == 0)
      {
         double progress_frac = double(image_counter)/double(n_images);
         outputfunc::print_elapsed_and_remaining_time(progress_frac);
      }

      string image_ID_str = annotated_bboxes_iter->first;
      vector<bounding_box> bboxes = annotated_bboxes_iter->second;
      string image_filename=labeled_faces_subdir+"image_"+
         image_ID_str+".jpg";

      for(unsigned int b = 0; b < bboxes.size(); b++)
      {
         texture_rectangle* tr_ptr = new texture_rectangle(
            image_filename, NULL);
         int xdim = tr_ptr->getWidth();
         int ydim = tr_ptr->getHeight();


// On 7/30/16, we empirically found that blacking out other faces
// appears to DECREASE gender classification performance!

// As of 7/31/16, we are unsure if blacking out other faces really
// hurts or not based upon caffe validation results on O(150K)
// augmented chips.

// Black out all face bboxes other than current one within current
// image:

         for(unsigned int b2 = 0; b2 < bboxes.size(); b2++)
         {
            if(b2 == b) continue;
            tr_ptr->fill_pixel_bbox(bboxes[b2], 0, 0, 0);
         }

         bounding_box curr_bbox = bboxes[b];
         string gender_value = curr_bbox.get_attribute_value("gender");
         string classification_value = curr_bbox.get_attribute_value(
            "classification_type");

         double mag_factor = 2;
         int px_center = curr_bbox.get_xcenter();
         int px_extent = curr_bbox.get_xextent();
         int px_start = px_center - mag_factor * 0.5 * px_extent;
         int px_stop = px_center + mag_factor * 0.5 * px_extent;
         px_start = basic_math::max(0, px_start);
         px_stop = basic_math::min(xdim-1, px_stop);

         int py_center = ydim - curr_bbox.get_ycenter();
         int py_extent = curr_bbox.get_yextent();
         int py_start = py_center - mag_factor * 0.5 * py_extent;
         int py_stop = py_center + mag_factor * 0.5 * py_extent;
         py_start = basic_math::max(0, py_start);
         py_stop = basic_math::min(ydim-1, py_stop);

         texture_rectangle* tr2_ptr = new texture_rectangle(
            xdim, ydim, 1, 3, NULL);

         int n_augmentations_per_chip = 1;
         if(gender_value != "unknown" && classification_value == "training")
         {
//            n_augmentations_per_chip = 1;
            n_augmentations_per_chip = 4;
         }

         for(int a = 0; a < n_augmentations_per_chip; a++)
         {
//            cout << "image_ID_str = " << image_ID_str 
//                 << " a = " << a << endl;

            tr2_ptr->copy_RGB_values(tr_ptr);
            
            int delta_x = 0;
            int delta_y = 0;
            if(a > 0)
            {
               delta_x = 2 * (nrfunc::ran1()-0.5) * 0.30 * px_extent;

// Intentionally bias vertical translation generally in the +gravity
// direction:
               delta_y = (2 * nrfunc::ran1()-1.25) * 0.30 * py_extent;
            }

            int qx_start = px_start + delta_x;
            int qx_stop = px_stop + delta_x;
            int qy_start = py_start + delta_y;
            int qy_stop = py_stop + delta_y;
            qx_start = basic_math::max(qx_start, 0);
            qx_stop = basic_math::min(qx_stop, xdim - 1);
            qy_start = basic_math::max(qy_start, 0);
            qy_stop = basic_math::min(qy_stop, ydim - 1);

            bool horiz_flipped_flag = false;
            if(a%2==1)
            {
               horiz_flipped_flag = true;
            }

            if(a > 0)
            {
               double delta_h = -30 + nrfunc::ran1() * 60;
               double delta_s = -0.25 + nrfunc::ran1() * 0.5;

// If rgb2grey_flag == true, effectively reset saturation to zero for
// some relatively small percentage of output tiles:

               if(rgb2grey_flag && nrfunc::ran1() < rgb2grey_threshold)
               {
                  delta_s = -1.5;
               }
               double delta_v = -0.25 + nrfunc::ran1() * 0.5;

               tr2_ptr->globally_perturb_hsv(
                  qx_start, qx_stop, 0, ydim - 1,
//                   qx_start, qx_stop, qy_start, qy_stop,
                  delta_h, delta_s, delta_v);
            }

            if(a > 0 && nrfunc::ran1() >= noise_threshold)
            {
               double noise_frac= 0.05 * nrfunc::ran1(); 
               double sigma = noise_frac * 255;
               tr2_ptr->add_gaussian_noise(
                  qx_start, qx_stop, qy_start, qy_stop, sigma);
            }

            string output_subdir=output_chips_subdir;
            if(gender_value == "unknown")
            {
               output_subdir += "unknown/";
            }
            else
            {
               output_subdir += classification_value+"/"+gender_value+"/";
            }
            string output_filename= output_subdir + 
               gender_value+"_face_"+image_ID_str+"_"
               +stringfunc::integer_to_string(a,2)+"_"
               +stringfunc::integer_to_string(face_ID++,5)+".png";

            tr2_ptr->write_curr_subframe(
               qx_start, qx_stop, qy_start, qy_stop, output_filename,
               horiz_flipped_flag);

            Magick::Image IM_image;
            IM_image.backgroundColor(Magick::Color(0,0,0));
            if(!videofunc::import_IM_image(output_filename, IM_image))
            {
               cout << "Unable to import " << output_filename << endl;
               continue;
            }
            
// As of 7/30/16, we experiment with doubling the size of any image
// chip whose horizontal pixel size < 0.5 * max_xdim and
// whose vertical pixel size < 0.5 * max_ydim:

            int qx_extent = qx_stop - qx_start;
            int qy_extent = qy_stop - qy_start;

            if(qx_extent < 0.5 * max_xdim && qy_extent < 0.5 * max_ydim)
            {
               Magick::Geometry newSize(2 * qx_extent, 2 * qy_extent);
               IM_image.zoom(newSize);
            }
            else
            {
               if(qx_extent > max_xdim || qy_extent > max_ydim)
               {
                  double aspect_ratio = double(qx_extent)/double(qy_extent);
                  double xratio=double(qx_extent)/double(max_xdim);
                  double yratio=double(qy_extent)/double(max_ydim);

                  int new_xdim, new_ydim;
                  if (xratio > yratio)
                  {
                     new_xdim=max_xdim;
                     new_ydim=new_xdim/aspect_ratio;
                  }
                  else
                  {
                     new_ydim=max_ydim;
                     new_xdim=aspect_ratio*new_ydim;
                  }
                  Magick::Geometry newSize(new_xdim, new_ydim);
                  IM_image.zoom(newSize);
               }
            }

// Randomly rotate image chip about its center through some relatively
// small angle theta measured in degs:

            if(a > 0)
            {
               double theta = 30 * 2 * (nrfunc::ran1() - 0.5);
               videofunc::crop_rotate_image(IM_image,theta);
            }
            videofunc::export_IM_image(output_filename, IM_image);

         } // loop over index a labeling augmentations
         
         delete tr2_ptr;
         delete tr_ptr;
      } // loop over index b labeling bounding boxes for current image

      image_counter++;
   } // loop over annotated_bboxes_iter

   int face_ID_stop = face_ID;
   double female_frac = double(n_female_bboxes) / n_total_bboxes;
   double male_frac = double(n_male_bboxes) / n_total_bboxes;
   
   cout << "n_total_bboxes = " << n_total_bboxes << endl;
   cout << "n_female_bboxes = " << n_female_bboxes << endl;
   cout << "n_male_bboxes = " << n_male_bboxes << endl;
   cout << "n_unknown_bboxes = " << n_unknown_bboxes << endl << endl;
   cout << "female_frac = " << female_frac << " male_frac = " << male_frac
        << endl;

   cout << "n_known_bboxes = " << n_known_bboxes << endl;
   cout << "n_training_bboxes = " << n_training_bboxes << endl;
   cout << "n_validation_bboxes = " << n_validation_bboxes << endl;
   cout << "n_testing_bboxes = " << n_testing_bboxes << endl;
   cout << "Starting face ID = " << face_ID_start << endl;
   cout << "Stopping face ID = " << face_ID_stop << endl;

   ofstream metastream;
   string augmentation_logfilename = "./augmentation.dat";
   filefunc::openfile(augmentation_logfilename, metastream);
   metastream << timefunc::getcurrdate() << endl << endl;
   metastream << "n_total_bboxes = " << n_total_bboxes << endl;
   metastream << "n_female_bboxes = " << n_female_bboxes << endl;
   metastream << "n_male_bboxes = " << n_male_bboxes << endl;
   metastream << "n_unknown_bboxes = " << n_unknown_bboxes << endl << endl;
   metastrea << "female_frac = " << female_frac << " male_frac = " << male_frac
             << endl;

   metastream << "n_known_bboxes = " << n_known_bboxes << endl;
   metastream << "n_training_bboxes = " << n_training_bboxes << endl;
   metastream << "n_validation_bboxes = " << n_validation_bboxes << endl;
   metastream << "n_testing_bboxes = " << n_testing_bboxes << endl;
   metastream << "Starting face ID = " << face_ID_start << endl;
   metastream << "Stopping face ID = " << face_ID_stop << endl;
   filefunc::closefile(augmentation_logfilename, metastream);
}

