// ========================================================================
// Program SYNTHESIZE_TOPIC_DOCS imports final.beta files
// generated by David Blei's Latent Dirichlet Allocation codes.  For
// each connected component within a specified image graph hierarchy,
// it generates a text document containing topic keywords whose
// repetition frequencies are proportional to the probabilities
// imported from the LDA-C beta files.  The synthesized text documents
// are exported to topic_subdir/topic_doc_NNN.txt.  The topic columns
// within the connected_components table of the IMAGERY database are also 
// updated.


/*

./synthesize_topic_docs                                              \
--region_filename ./bundler/textdocs/reuters/packages/peter_inputs.pkg \
--GIS_layer ./packages/imagery_metadata.pkg 

*/

// ========================================================================
// Last updated on 12/29/12
// ========================================================================

#include <algorithm>
#include <iostream>
#include <map>
#include <string>
#include <vector>
#include "gmm/gmm.h"
#include "gmm/gmm_matrix.h"

#include "general/filefuncs.h"
#include "math/genvector.h"
#include "graphs/graphdbfuncs.h"
#include "image/graphicsfuncs.h"
#include "templates/mytemplates.h"
#include "general/outputfuncs.h"
#include "passes/PassesGroup.h"
#include "osg/osgGIS/postgis_databases_group.h"
#include "math/prob_distribution.h"
#include "general/stringfuncs.h"
#include "general/sysfuncs.h"
#include "time/timefuncs.h"
#include "datastructures/union_find.h"

// ==========================================================================
int main( int argc, char** argv )
{
   using std::cin;
   using std::cout;
   using std::endl;
   using std::flush;
   using std::map;
   using std::ofstream;
   using std::string;
   using std::vector;
   std::set_new_handler(sysfunc::out_of_memory);

//   bool modify_IMAGERY_database_flag=true;
   bool modify_IMAGERY_database_flag=false;
   if (modify_IMAGERY_database_flag)
   {
      cout << "modify_IMAGERY_database_flag = true" << endl;
   }
   else
   {
      cout << "modify_IMAGERY_database_flag = false" << endl;
   }
   outputfunc::enter_continue_char();


// Use an ArgumentParser object to manage the program arguments:

   osg::ArgumentParser arguments(&argc,argv);
   PassesGroup passes_group(&arguments);

   vector<int> GISlayer_IDs=passes_group.get_GISlayer_IDs();
//   cout << "GISlayer_IDs.size() = " << GISlayer_IDs.size() << endl;

//   bool astro_flag=false;
//   bool reuters_flag=true;
   string arXiv_subdir="/media/66368D22368CF3F9/visualization/arXiv/";
   string astro_subdir=arXiv_subdir+"astro/";
   string reuters_subdir=arXiv_subdir+"reuters/export/";
//   string text_subdir=astro_subdir+"txt/";
   string text_subdir=reuters_subdir+"text/";
   string ccs_subdir=text_subdir+"connected_components/";
   string topic_docs_subdir=ccs_subdir+"topic_docs/";
   filefunc::dircreate(topic_docs_subdir);

// Instantiate postgis database objects to send data to and retrieve
// data from external Postgres database:

   postgis_databases_group* postgis_databases_group_ptr=
      new postgis_databases_group;
   postgis_database* postgis_db_ptr=postgis_databases_group_ptr->
      generate_postgis_database_from_GISlayer_IDs(
         passes_group,GISlayer_IDs);
//   cout << "postgis_db_ptr = " << postgis_db_ptr << endl;


// Import word list from bag of words generated by TEXT2WORDS into
// multi_doc_word_map:

   string bag_filename=text_subdir+"all_docs.wordbag";
   filefunc::ReadInfile(bag_filename);

//   int min_corpus_word_freq=0;
   int min_corpus_word_freq=10;
//   cout << "Enter min word frequency within documents:" << endl;
//   cin >> min_corpus_word_freq;

   vector<string> word_list;
   for (unsigned int i=0; i<filefunc::text_line.size(); i++)
   {
      string curr_line=filefunc::text_line[i];
      vector<string> substrings=
         stringfunc::decompose_string_into_substrings(curr_line);
      string curr_word=substrings[1];

      int corpus_freq=stringfunc::string_to_number(substrings[2]);
      if (corpus_freq < min_corpus_word_freq) continue;

      word_list.push_back(curr_word);
   } // loop over index i labeling lines in all_docs.wordbag

   int n_words=word_list.size();
   cout << "word_list.size() = " << n_words << endl;

// Retrieve number of connected components for specified graph hierarchy:

   int hierarchy_ID=9;	// Reuters 43K
   int n_levels=graphdbfunc::retrieve_n_levels_for_particular_graph_hierarchy(
      postgis_db_ptr,hierarchy_ID);
   int n_ccs=graphdbfunc::get_n_connected_components(
      postgis_db_ptr,hierarchy_ID);
   cout << "Number connected components = " << n_ccs << endl;

//    int n_topics_per_cc=5;   // equivalent to "image_width"
//   int n_words_per_topic=5;
//   int n_words_per_topic=10;
   int n_words_per_topic=20;
   cout << "Enter number of words per topic" << endl;
   cin >> n_words_per_topic;

// Loop over all connected components and import their topic
// distributions from the final.beta files generated by LDA-C.  Store
// all topic distributions within LOG_PROBS_MAP as function of unique
// topic_ID key:

   for (int cc=0; cc<n_ccs; cc++)
   {
      cout << cc << " " << flush;

      string cc_substring="_"+stringfunc::integer_to_string(cc,3);
      string topics_subdir=ccs_subdir+"topics_"+stringfunc::integer_to_string(
         cc,3)+"/";
//      cout << "topics_subdir = " << topics_subdir << endl;
      string beta_filename=topics_subdir+"final.beta";
//      cout << "Beta_filename = " << beta_filename << endl;
      filefunc::ReadInfile(beta_filename);

      string topic_doc_filename=topic_docs_subdir+"topic_doc"+cc_substring
         +".txt";
      ofstream topic_doc_stream;
      filefunc::openfile(topic_doc_filename,topic_doc_stream);

      for (unsigned int t=0; t<filefunc::text_line.size(); t++)
      {
         vector<double> curr_log_probs=
            stringfunc::string_to_numbers(filefunc::text_line[t]);
         vector<int> word_indices;
         for (int w=0; w<n_words; w++)
         {
            word_indices.push_back(w);
         }

         templatefunc::Quicksort_descending(curr_log_probs,word_indices);

// Synthesize a new text document containing topic keywords whose
// repetition frequencies are proportional to the probabilities
// imported from the LDA-C beta file:

//         cout << "cc = " << cc << " t = " << t << endl;
         double min_weight=exp(curr_log_probs[n_words_per_topic-1]);
         string curr_topic;
         for (int w=0; w<n_words_per_topic; w++)
         {
            string curr_word=word_list[word_indices[w]];
            curr_topic += stringfunc::capitalize_word(curr_word);
            if (w < n_words_per_topic-1) curr_topic += ",";

            double weight=exp(curr_log_probs[w])/min_weight;
//            cout << "curr_word = " << curr_word
//                 << " weight = " << weight << endl;
            int n_freq=basic_math::round(weight);
            for (int f=0; f<n_freq; f++)
            {
               topic_doc_stream << curr_word << " ";
            }
            
         } // loop over index w labeling words within current topic
         topic_doc_stream << endl;

//         cout << "cc = " << cc << " t = " << t 
//              << " curr_topic = " << curr_topic << endl;

         if (modify_IMAGERY_database_flag)
         {
            for (int graph_ID=0; graph_ID<n_levels; graph_ID++)
            {
               graphdbfunc::update_connected_component_topic(
                  postgis_db_ptr,hierarchy_ID,graph_ID,
                  cc,t,curr_topic);
            }
         }
         
      } // loop over index t labeling topics for current cc

//      outputfunc::enter_continue_char();
      filefunc::closefile(topic_doc_filename,topic_doc_stream);

//      outputfunc::enter_continue_char();

   } // loop over index cc labeling connected components
   cout << endl;

}

