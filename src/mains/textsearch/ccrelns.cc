// ========================================================================
// Program CCRELNS 
// ========================================================================
// Last updated on 12/27/12; 12/28/12
// ========================================================================

#include <algorithm>
#include <iostream>
#include <map>
#include <string>
#include <vector>
#include "dlib/clustering/modularity_clustering.h"
#include "gmm/gmm.h"
#include "gmm/gmm_matrix.h"

#include "general/filefuncs.h"
#include "math/genvector.h"
#include "graphs/graphdbfuncs.h"
#include "image/graphicsfuncs.h"
#include "templates/mytemplates.h"
#include "general/outputfuncs.h"
#include "passes/PassesGroup.h"
#include "osg/osgGIS/postgis_databases_group.h"
#include "math/prob_distribution.h"
#include "general/stringfuncs.h"
#include "general/sysfuncs.h"
#include "time/timefuncs.h"
#include "datastructures/union_find.h"

// ==========================================================================
int main( int argc, char** argv )
{
   using std::cin;
   using std::cout;
   using std::endl;
   using std::flush;
   using std::map;
   using std::ofstream;
   using std::string;
   using std::vector;
   std::set_new_handler(sysfunc::out_of_memory);

// Use an ArgumentParser object to manage the program arguments:

   osg::ArgumentParser arguments(&argc,argv);
   const int ndims=3;
   PassesGroup passes_group(&arguments);

   int cloudpass_ID=passes_group.get_curr_cloudpass_ID();
   vector<int> GISlayer_IDs=passes_group.get_GISlayer_IDs();
//   cout << "GISlayer_IDs.size() = " << GISlayer_IDs.size() << endl;

   bool astro_flag=false;
   bool reuters_flag=true;
   string arXiv_subdir="/media/66368D22368CF3F9/visualization/arXiv/";
   string astro_subdir=arXiv_subdir+"astro/";
   string reuters_subdir=arXiv_subdir+"reuters/export/";
//   string text_subdir=astro_subdir+"txt/";
   string text_subdir=reuters_subdir+"text/";
   string ccs_subdir=text_subdir+"connected_components/";
   filefunc::dircreate(ccs_subdir);

// Instantiate postgis database objects to send data to and retrieve
// data from external Postgres database:

   postgis_databases_group* postgis_databases_group_ptr=
      new postgis_databases_group;
   postgis_database* postgis_db_ptr=postgis_databases_group_ptr->
      generate_postgis_database_from_GISlayer_IDs(
         passes_group,GISlayer_IDs);
//   cout << "postgis_db_ptr = " << postgis_db_ptr << endl;

// Retrieve number of connected components for specified graph hierarchy:

   int hierarchy_ID=9;	// Reuters 43K
   int n_ccs=graphdbfunc::get_n_connected_components(
      postgis_db_ptr,hierarchy_ID);
   cout << "Number connected components = " << n_ccs << endl;

   const int ascii_a=97;
   const int ascii_z=122;
   const int ascii_A=65;
   const int ascii_Z=90;
   const int ascii_hyphen=45;

   typedef map<string,int> WORD_MAP;
   WORD_MAP::iterator word_iter,stop_word_iter,curr_word_iter;
   WORD_MAP multi_doc_word_map,stop_word_map;

// Import word list from bag of words generated by TEXT2WORDS into
// multi_doc_word_map:

   string bag_filename=text_subdir+"all_docs.wordbag";
   filefunc::ReadInfile(bag_filename);

//   int min_corpus_word_freq=0;
   int min_corpus_word_freq=10;
//   cout << "Enter min word frequency within documents:" << endl;
//   cin >> min_corpus_word_freq;

   int word_ID=0;
   vector<string> word_list,sorted_word_list;
   for (int i=0; i<filefunc::text_line.size(); i++)
   {
      string curr_line=filefunc::text_line[i];
      vector<string> substrings=
         stringfunc::decompose_string_into_substrings(curr_line);
      string curr_word=substrings[1];

      int corpus_freq=stringfunc::string_to_number(substrings[2]);
      if (corpus_freq < min_corpus_word_freq) continue;

      word_iter=multi_doc_word_map.find(curr_word);
      if (word_iter != multi_doc_word_map.end())
      {
         cout << "curr_word = " << curr_word << " already exists!" 
              << endl;
         outputfunc::enter_continue_char();
      }
      
      multi_doc_word_map[curr_word]=word_ID;
      word_list.push_back(curr_word);
      sorted_word_list.push_back(curr_word);
    
      word_ID++;
   } // loop over index i labeling lines in all_docs.wordbag

   int n_words=multi_doc_word_map.size();
   cout << "n_words = multi_doc_word_map.size() = " << n_words << endl;
   cout << "word_list.size() = " << word_list.size() << endl;

/*
// Export word list to output text file:

   string wordlist_filename=text_subdir+"word_list.dat";
   ofstream word_stream;
   filefunc::openfile(wordlist_filename,word_stream);   
   for (int w=0; w<word_list.size(); w++)
   {
      word_stream << word_list[w] << endl;
   }
   filefunc::closefile(wordlist_filename,word_stream);   
   string banner="Exported word list to "+wordlist_filename;
   outputfunc::write_banner(banner);
*/

// Instantiate STL map to hold topic distributions over words:

   typedef map<string,int> WORD_MAP;
//   WORD_MAP::iterator word_iter,stop_word_iter;
   WORD_MAP cc_words_map;

// dependent var = word
// independent var = word index


   typedef map<int,vector<int>* > CC_TOPIC_WORDS_MAP;

// independent var = connected component ID
// dependent var = indices for dominant topic words within cc

   CC_TOPIC_WORDS_MAP::iterator cc_topic_words_iter;
   CC_TOPIC_WORDS_MAP cc_topic_words_map;

   int n_topics_per_cc=5;   // equivalent to "image_width"
//   int n_words_per_topic=5;
//   int n_words_per_topic=10;
   int n_words_per_topic=20;
   cout << "Enter number of words per topic" << endl;
   cin >> n_words_per_topic;

// Loop over all connected components and import their topic
// distributions from the final.beta files generated by LDA-C.  Store
// all topic distributions within LOG_PROBS_MAP as function of unique
// topic_ID key:

   genmatrix* cc_word_matrix_ptr=new genmatrix(n_words,n_ccs);

   union_find* union_find_ptr=new union_find();

   for (int cc=0; cc<n_ccs; cc++)
   {
      cout << cc << " " << flush;
      union_find_ptr->MakeSet(cc);

      string cc_substring="_"+stringfunc::integer_to_string(cc,3);
      string topics_subdir=ccs_subdir+"topics_"+stringfunc::integer_to_string(
         cc,3)+"/";
//      cout << "topics_subdir = " << topics_subdir << endl;
      string beta_filename=topics_subdir+"final.beta";
//      cout << "Beta_filename = " << beta_filename << endl;
      filefunc::ReadInfile(beta_filename);

      for (int t=0; t<filefunc::text_line.size(); t++)
      {
         vector<double> curr_log_probs=
            stringfunc::string_to_numbers(filefunc::text_line[t]);
         vector<int> word_indices;
         for (int w=0; w<n_words; w++)
         {
            word_indices.push_back(w);
         }

         templatefunc::Quicksort_descending(curr_log_probs,word_indices);

//         cout << "cc = " << cc << " t = " << t << endl;
         for (int w=0; w<n_words_per_topic; w++)
         {
            string curr_word=word_list[word_indices[w]];
            word_iter=cc_words_map.find(curr_word);
//            cout << "   " << curr_word ;
            if (word_iter==cc_words_map.end())
            {
               cc_words_map[curr_word]=1;
            }
            else
            {
               word_iter->second=word_iter->second+1;
            }
//            cout << endl;
         }
      } // loop over index t labeling topics for current cc

// Convert STL word map into binary vector for all topic words for
// current connected component:

      genvector curr_cc_column(n_words);
      curr_cc_column.clear_values();
      for (word_iter=cc_words_map.begin(); word_iter != cc_words_map.end();
           word_iter++)
      {
         string curr_word=word_iter->first;
         int word_frequency=word_iter->second;

         curr_word_iter=multi_doc_word_map.find(curr_word);
         int word_index=curr_word_iter->second;
         curr_cc_column.put(word_index,word_frequency);
      }
      cc_words_map.clear();

      curr_cc_column=curr_cc_column.unitvector();
      cc_word_matrix_ptr->put_column(cc,curr_cc_column);

   } // loop over index cc labeling connected components
   cout << endl;

// Instantiate n_ccs x n_ccs matrix to hold "connected component
// adjacency matrix" generated from dot products of column vectors in
// *cc_word_matrix_ptr:

   genmatrix cc_adjacency(n_ccs,n_ccs);
   cc_adjacency.clear_values();

//   double min_dotproduct=0.001;
//   double min_dotproduct=0.1;
//   double min_dotproduct=0.2;
   double min_dotproduct=0.33;
   cout << "Enter minimum dotproduct:" << endl;
   cin >> min_dotproduct;

   vector<dlib::sample_pair> sample_pairs;

   vector<double> dotproducts;
   genvector cc_column1(n_words),cc_column2(n_words);
   for (int cc1=0; cc1<n_ccs; cc1++)
   {
      cout << cc1 << " " << flush;
      cc_word_matrix_ptr->get_column(cc1,cc_column1);
      for (int cc2=0; cc2<n_ccs; cc2++)
      {
         cc_word_matrix_ptr->get_column(cc2,cc_column2);
         double dotproduct=cc_column1.dot(cc_column2);
         dotproducts.push_back(dotproduct);

         if (dotproduct < min_dotproduct) continue;

         union_find_ptr->Link(cc1,cc2);

         cc_adjacency.put(cc1,cc2,dotproduct);
         sample_pairs.push_back(dlib::sample_pair(cc1,cc2,dotproduct));
      } // loop over index cc2 labeling connected component
   } // loop over index cc1 labeling connected component
   
//    cout << "cc_adjacency = " << cc_adjacency << endl;
   cout << "sample_pairs.size() = " << sample_pairs.size() << endl;


   prob_distribution prob(dotproducts,100);
   prob.writeprobdists(false);

//   vector<unsigned long> cluster_labels;
//   dlib::newman_cluster (sample_pairs,cluster_labels);


   typedef map<int,vector<int>* > CC_CLUSTERS_MAP;

// independent var = connected component ID
// dependent var = indices for dominant topic words within cc

   CC_CLUSTERS_MAP::iterator cc_clusters_iter;
   CC_CLUSTERS_MAP cc_clusters_map;

   string cluster_filename="clusters.dat";
   ofstream cluster_stream;
   filefunc::openfile(cluster_filename,cluster_stream);

   int cluster_ID=0;
   for (int cc=0; cc<n_ccs; cc++)
   {
      int root_ID=union_find_ptr->Find(cc);

      cc_clusters_iter=cc_clusters_map.find(root_ID);
      if (cc_clusters_iter==cc_clusters_map.end())
      {
         vector<int>* V_ptr=new vector<int>;
         V_ptr->push_back(cc);
//         cc_clusters_map[root_ID]=V_ptr;
         cc_clusters_map[cluster_ID++]=V_ptr;
      }
      else
      {
         vector<int>* V_ptr=cc_clusters_iter->second;
         V_ptr->push_back(cc);
      }

      cluster_stream << "cc_ID = " << cc
                     << " root_ID = " << root_ID
                     << " cc_clusters_map.size() = " << cc_clusters_map.size()
                     << endl;

   } // loop over index cc labeling connected components
   delete union_find_ptr;

   cluster_stream << endl << endl;

   cout << "cc_clusters_map.size() = " << cc_clusters_map.size() << endl;

   int counter=0;
   int nontrivial_cluster_counter=1;
   int n_clusters=cc_clusters_map.size();
   int n_ccs_in_nontrivial_clusters=0;
   for (cc_clusters_iter=cc_clusters_map.begin(); 
        cc_clusters_iter != cc_clusters_map.end(); cc_clusters_iter++)
   {
      int cluster_ID=cc_clusters_iter->first;
      vector<int>* cc_IDs_ptr=cc_clusters_iter->second;

      cout << "counter = " << counter++
           << " cluster_ID = " << cluster_ID
           << " cc_IDs_ptr = " << cc_IDs_ptr << endl;

      if (cc_IDs_ptr->size() <= 1) continue;

      cluster_stream << nontrivial_cluster_counter++
                     << "   cluster label = " << cluster_ID << endl;
      cluster_stream << "   ";
      n_ccs_in_nontrivial_clusters += cc_IDs_ptr->size();
      
      for (int j=0; j<cc_IDs_ptr->size(); j++)
      {
         cluster_stream << cc_IDs_ptr->at(j) << " ";
      }
      cluster_stream << endl << endl;
   }
   
   cluster_stream << "Min dotproduct = " << min_dotproduct << endl;
   cluster_stream << "n_clusters = " << n_clusters << endl;
   cluster_stream << "n_ccs_in_nontrivial_clusters = "
                  << n_ccs_in_nontrivial_clusters << endl;
   cluster_stream << "n_words_per_topic = " << n_words_per_topic << endl;
   filefunc::closefile(cluster_filename,cluster_stream);
}

