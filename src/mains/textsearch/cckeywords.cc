// ========================================================================
// Program CCKEYWORDS iterates over all connected components within
// a specified image graph hierarchy.  For each component, it
// imports the text files corresponding to node members.  Sparse word
// histograms are written to an output file which can be ingested by
// David Blei's Latent Dirichlet Allocation codes.  An executable
// script that calls Blei's codes is also generated by CCKEYWORDS.
// When the script is run, the top 5 terms in the top 5 topics for
// each connected component are written to an output file within a
// topics subdirectory of the connected components directory.

// ./cckeywords                                                         
// --region_filename ./bundler/textdocs/reuters/packages/peter_inputs.pkg 
// --GIS_layer ./packages/imagery_metadata.pkg 

// ========================================================================
// Last updated on 12/26/12
// ========================================================================

#include <algorithm>
#include <iostream>
#include <map>
#include <string>
#include <vector>
#include "gmm/gmm.h"
#include "gmm/gmm_matrix.h"

#include "general/filefuncs.h"
#include "math/genvector.h"
#include "graphs/graphdbfuncs.h"
#include "video/imagesdatabasefuncs.h"
#include "templates/mytemplates.h"
#include "general/outputfuncs.h"
#include "passes/PassesGroup.h"
#include "osg/osgGIS/postgis_databases_group.h"
#include "general/stringfuncs.h"
#include "general/sysfuncs.h"
#include "time/timefuncs.h"

// ==========================================================================
int main( int argc, char** argv )
{
   using std::cin;
   using std::cout;
   using std::endl;
   using std::flush;
   using std::map;
   using std::ofstream;
   using std::string;
   using std::vector;
   std::set_new_handler(sysfunc::out_of_memory);

// Use an ArgumentParser object to manage the program arguments:

   osg::ArgumentParser arguments(&argc,argv);
   const int ndims=3;
   PassesGroup passes_group(&arguments);

   int cloudpass_ID=passes_group.get_curr_cloudpass_ID();
   vector<int> GISlayer_IDs=passes_group.get_GISlayer_IDs();
//   cout << "GISlayer_IDs.size() = " << GISlayer_IDs.size() << endl;

   bool astro_flag=false;
   bool reuters_flag=true;
   string arXiv_subdir="/media/66368D22368CF3F9/visualization/arXiv/";
   string astro_subdir=arXiv_subdir+"astro/";
   string reuters_subdir=arXiv_subdir+"reuters/export/";
//   string text_subdir=astro_subdir+"txt/";
   string text_subdir=reuters_subdir+"text/";
   string ccs_subdir=text_subdir+"connected_components/";
   filefunc::dircreate(ccs_subdir);

// Instantiate postgis database objects to send data to and retrieve
// data from external Postgres database:

   postgis_databases_group* postgis_databases_group_ptr=
      new postgis_databases_group;
   postgis_database* postgis_db_ptr=postgis_databases_group_ptr->
      generate_postgis_database_from_GISlayer_IDs(
         passes_group,GISlayer_IDs);
//   cout << "postgis_db_ptr = " << postgis_db_ptr << endl;

// Retrieve number of connected components for specified graph hierarchy:

   int hierarchy_ID=9;	// Reuters 43K
   int n_ccs=graphdbfunc::get_n_connected_components(
      postgis_db_ptr,hierarchy_ID);
   cout << "Number connected components = " << n_ccs << endl;

   const int ascii_a=97;
   const int ascii_z=122;
   const int ascii_A=65;
   const int ascii_Z=90;
   const int ascii_hyphen=45;

   typedef map<string,int> WORD_MAP;
   WORD_MAP::iterator word_iter,stop_word_iter;
   WORD_MAP multi_doc_word_map,stop_word_map;

// Import word list from bag of words generated by TEXT2WORDS into
// multi_doc_word_map:

   string bag_filename=text_subdir+"all_docs.wordbag";
   filefunc::ReadInfile(bag_filename);

//   int min_corpus_word_freq=0;
   int min_corpus_word_freq=10;
//   cout << "Enter min word frequency within documents:" << endl;
//   cin >> min_corpus_word_freq;

   int word_ID=0;
   vector<string> word_list,sorted_word_list;
   for (int i=0; i<filefunc::text_line.size(); i++)
   {
      string curr_line=filefunc::text_line[i];
      vector<string> substrings=
         stringfunc::decompose_string_into_substrings(curr_line);
      string curr_word=substrings[1];

      int corpus_freq=stringfunc::string_to_number(substrings[2]);
      if (corpus_freq < min_corpus_word_freq) continue;

      word_iter=multi_doc_word_map.find(curr_word);
      if (word_iter != multi_doc_word_map.end())
      {
         cout << "curr_word = " << curr_word << " already exists!" 
              << endl;
         outputfunc::enter_continue_char();
      }
      
      multi_doc_word_map[curr_word]=word_ID;
      word_list.push_back(curr_word);
      sorted_word_list.push_back(curr_word);
    
      word_ID++;
   } // loop over index i labeling lines in all_docs.wordbag

   int n_words=multi_doc_word_map.size();
   cout << "multi_doc_word_map.size() = " << n_words << endl;
   cout << "word_list.size() = " << word_list.size() << endl;

/*
// Export word list to output text file:

   string wordlist_filename=text_subdir+"word_list.dat";
   ofstream word_stream;
   filefunc::openfile(wordlist_filename,word_stream);   
   for (int w=0; w<word_list.size(); w++)
   {
      word_stream << word_list[w] << endl;
   }
   filefunc::closefile(wordlist_filename,word_stream);   
   string banner="Exported word list to "+wordlist_filename;
   outputfunc::write_banner(banner);
*/

// Import stop word list downloaded from web and augmented by us:

   string stoplist_filename="./stop_list.txt";
   filefunc::ReadInfile(stoplist_filename);

   for (int i=0; i<filefunc::text_line.size(); i++)
   {
      string stop_word=filefunc::text_line[i];
      stop_word=stringfunc::remove_leading_whitespace(stop_word);
      stop_word=stringfunc::remove_trailing_whitespace(stop_word);
      stop_word_map[stop_word]=-1;
//      cout << i << "   stop_word = " << stop_word 
//           << " word size = " << stop_word.size() << endl;
   }
   cout << "stop_word_map.size() = " << stop_word_map.size() << endl;

// Open script which will contain commands to run David Blei's Latent
// Dirichlet Allocation codes on document-word matrices generated for
// each connected component:

   string lda_filename=ccs_subdir+"run_lda";
   ofstream lda_stream;
   filefunc::openfile(lda_filename,lda_stream);

// Loop over connected components starts here:

   int cc_start=0;
//   int cc_start=100;
//   int cc_stop=cc_start+3;
   int cc_stop=n_ccs;
   for (int cc=cc_start; cc<cc_stop; cc++)
   {
      string cc_substring="_"+stringfunc::integer_to_string(cc,3);

      string doc_words_filename=ccs_subdir+"doc_words"+cc_substring+".dat";
      ofstream doc_words_stream;
      filefunc::openfile(doc_words_filename,doc_words_stream);

// Retrieve image URLs corresponding to current connected component
// from postgis database:

      vector<string> image_URLs;
      imagesdatabasefunc::get_connected_component_image_URLs(
         postgis_db_ptr,hierarchy_ID,cc,image_URLs);

      int n_text_files=image_URLs.size();

      genvector* term_frequency_ptr=new genvector(n_words);
      genvector* ndocs_containing_term_ptr=new genvector(n_words);
      ndocs_containing_term_ptr->clear_values();
      cout << "n_text_files = " << n_text_files
           << " n_words = " << n_words << endl;
      
      gmm::row_matrix< gmm::wsvector<float> >* term_freq_sparse_matrix_ptr=
         new gmm::row_matrix< gmm::wsvector<float> >(n_text_files,n_words);
      gmm::clear(*term_freq_sparse_matrix_ptr);

// Import text files corresponding to image URLs for current connected
// component:

      vector<string> text_filenames;
      for (int n=0; n<n_text_files; n++)
      {
         string basename=filefunc::getbasename(image_URLs[n]);
         string text_filename=filefunc::replace_suffix(basename,"txt");
         text_filename=text_subdir+text_filename;
         text_filenames.push_back(text_filename);
         cout << cc << "  " << n << "  " 
              << filefunc::getbasename(text_filename) << endl;

         filefunc::ReadInfile(text_filename);
         term_frequency_ptr->clear_values();

         bool introduction_found_flag=false;      
         bool reuters_end_found_flag=false;
         int n_document_strings=0;
         for (int i=0; i<filefunc::text_line.size(); i++)
         {
            string curr_line=filefunc::text_line[i];
            vector<string> substrings=
               stringfunc::decompose_string_into_substrings(curr_line);
            for (int s=0; s<substrings.size(); s++)
            {
               string curr_substring=substrings[s];

// Ignore numbers:

               if (stringfunc::is_number(curr_substring)) continue;

// Search for keywords near end of Reuters' articles:

               if (reuters_flag)
               {
                  if (curr_substring=="(Reporting" ||
                  curr_substring=="(reporting" || 
                  curr_substring=="(Reported" ||
                  curr_substring=="(reported")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Editing" ||
                  curr_substring=="(editing" || curr_substring=="(Edited" ||
                  curr_substring=="(edited")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Additional" ||
                  curr_substring=="(additional" || curr_substring=="(Added" ||
                  curr_substring=="(added")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Writing" ||
                  curr_substring=="(writing" || curr_substring=="(Written" ||
                  curr_substring=="(written")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Created" ||
                  curr_substring=="(created")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Compiled" ||
                  curr_substring=="(compiled")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Via" ||
                  curr_substring=="(via")
                  {
                     reuters_end_found_flag=true;
                  }
                  else if (curr_substring=="(Sources:" ||
                  curr_substring=="(sources" || curr_substring=="(SOURCES:" ||
                  curr_substring=="(SOURCE:"|| curr_substring=="(source:" ||
                  curr_substring=="Sources:" || curr_substring=="sources:" ||
                  curr_substring=="SOURCES:" || curr_substring=="SOURCE:")
                  {
                     reuters_end_found_flag=true;
                  }
               } // reuters_flag conditional
               if (reuters_end_found_flag) break;

// Remove non-letters from strings:

               vector<int> ascii_string=
                  stringfunc::decompose_string_to_ascii_rep(curr_substring);

               string cleaned_substring;
               for (int s=0; s<ascii_string.size(); s++)
               {
                  int curr_ascii=ascii_string[s];
                  if (curr_ascii >= ascii_a && curr_ascii <= ascii_z)
                  {
                     cleaned_substring.push_back(curr_substring[s]);
                  }

// Convert uppercase letters to lowercase:

                  if (curr_ascii >= ascii_A && curr_ascii <= ascii_Z)
                  {
                     curr_ascii += ascii_a-ascii_A;
                     char new_char=stringfunc::ascii_integer_to_char(
                        curr_ascii);
                     cleaned_substring.push_back(new_char);
                  }
               }
               cleaned_substring=
                  stringfunc::remove_leading_whitespace(cleaned_substring);
               cleaned_substring=
                  stringfunc::remove_trailing_whitespace(cleaned_substring);
         
               if (astro_flag)
               {
                  if (cleaned_substring=="introduction")
                  {
                     cout << "Introduction found" << endl;
                     introduction_found_flag=true;
                  }
                  else if (cleaned_substring=="pacs")
                  {
                     cout << "PACS found" << endl;
                     introduction_found_flag=true;
                  }
                  else if (cleaned_substring=="keywords")
                  {
                     cout << "Keywords found" << endl;
                     introduction_found_flag=true;
                  }
                  else if (cleaned_substring=="contents")
                  {
                     cout << "contents found" << endl;
                     introduction_found_flag=true;
                  }
                  else if (cleaned_substring=="subject")
                  {
                     cout << "subject found" << endl;
                     introduction_found_flag=true;
                  }
                  if (introduction_found_flag) break;

               } // astro_flag conditional
            

// Ignore short strings:

               if (cleaned_substring.size() < 3) continue;

// Ignore "words" containing "garbage":

               vector<string> garbage_strings;
               garbage_strings.push_back("qqq");
               garbage_strings.push_back("xxx");

               bool garbage_continue_flag=false;
               for (int g=0; g<garbage_strings.size(); g++)
               {
                  int garbage_location=stringfunc::first_substring_location(
                     cleaned_substring,garbage_strings[g]);
                  if (garbage_location > 0) 
                  {
                     cout << "garbage_string = " << garbage_strings[g]
                          << " cleaned_substring = " << cleaned_substring
                          << endl;
                     garbage_continue_flag=true;
//                  outputfunc::enter_continue_char();
                  }
               }
               if (garbage_continue_flag) continue;

// Stem cleaned substring:

// FAKE FAKE:  Sun Dec 23, 2012 at 2 pm
// Experiment with NOT stemming:

               string stemmed_substring=cleaned_substring;

/*
  string stemmed_substring=stringfunc::stem_word(cleaned_substring);
  stemmed_substring=
  stringfunc::remove_leading_whitespace(stemmed_substring);
  stemmed_substring=
  stringfunc::remove_trailing_whitespace(stemmed_substring);
*/

// Ignore stemmed strings which match "stop" words:

               stop_word_iter=stop_word_map.find(stemmed_substring);
               if (stop_word_iter != stop_word_map.end()) continue;

               word_iter=multi_doc_word_map.find(stemmed_substring);
               if (word_iter != multi_doc_word_map.end())
               {
                  int word_index=word_iter->second;
                  int word_freq=term_frequency_ptr->get(word_index);
                  term_frequency_ptr->put(word_index,word_freq+1);
                  n_document_strings++;
               }
            } // loop over index s labeling substring in current line
         } // loop over index i labeling line within current text file

// Export word histogram for current document in sparse format required 
// by David Blei's Latent Dirichlet Allocation LDA-C code:

         int term_counter=0;
         for (int t=0; t<n_words; t++)
         {
            int curr_term_count=term_frequency_ptr->get(t);
            if (curr_term_count > 0) term_counter++;
         }

         doc_words_stream << term_counter << " " << flush;
         for (int t=0; t<n_words; t++)
         {
            int curr_term_count=term_frequency_ptr->get(t);
            if (curr_term_count==0) continue;
            term_counter++;
            doc_words_stream  << t << ":" << curr_term_count << " " << flush;
         }
         doc_words_stream << endl;
      } // loop over index n labeling URL within current connected component
      delete term_frequency_ptr;

// In order for Blei's topics.py PERL script to extract leading words
// corresponding to top topics, we have empirically found that the
// output doc_words.dat file must contain at least one instance of the
// final term in the overall word list.  So we manually add one final
// line to the doc_words.dat to ensure this condition:

      doc_words_stream << "1 " << n_words-1 << ":1" << endl;
      filefunc::closefile(doc_words_filename,doc_words_stream);

      delete ndocs_containing_term_ptr;
      delete term_freq_sparse_matrix_ptr;

      string topics_subdir=ccs_subdir+"topics_"+stringfunc::integer_to_string(
         cc,3);
      filefunc::dircreate(topics_subdir);


      string lda_cmd="/usr/local/bin/lda/lda est 0.05 5 ";
      lda_cmd += "/usr/local/bin/lda/settings.txt "+
         filefunc::getbasename(doc_words_filename);
      lda_cmd += " random ./"+filefunc::getbasename(topics_subdir);

      string python_cmd="python /usr/local/bin/lda/topics.py ";
      python_cmd += "./"+filefunc::getbasename(topics_subdir)+"/final.beta ";
      python_cmd += "../word_list.dat 5 > ";
      python_cmd += "./"+filefunc::getbasename(topics_subdir)+"/topics.dat";

      lda_stream << lda_cmd << endl;
      lda_stream << python_cmd << endl;
      lda_stream << endl;


   } // loop over index cc labeling connected components

   filefunc::closefile(lda_filename,lda_stream);
   string unix_cmd="chmod a+x "+lda_filename;
   sysfunc::unix_command(unix_cmd);

   string banner="Exported executable script "+lda_filename;
   outputfunc::write_big_banner(banner);
}

